{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, in line-up prediction we cannot use a whole year as the test set. Since many changes have been occured (data shift), we have many new players this year and many retired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnb2Fl8bHUP_",
    "outputId": "7de81def-3dcf-4024-fd15-c3fae1e4713e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27500\n",
      "26593\n",
      "26407\n",
      "26344\n",
      "26447\n",
      "21241\n",
      "len of final df: 154532\n",
      "first print \n",
      "        outcome  season home_team away_team  starting_min  end_min  \\\n",
      "0            -1    2007       LAL       PHO             0        5   \n",
      "1            -1    2007       LAL       PHO             6        7   \n",
      "2             1    2007       LAL       PHO             8        9   \n",
      "3             1    2007       LAL       PHO            10       10   \n",
      "4            -1    2007       LAL       PHO            11       11   \n",
      "...         ...     ...       ...       ...           ...      ...   \n",
      "154527       -1    2012       CHA       NOH            38       39   \n",
      "154528       -1    2012       CHA       NOH            40       41   \n",
      "154529       -1    2012       CHA       NOH            42       42   \n",
      "154530       -1    2012       CHA       NOH            43       45   \n",
      "154531       -1    2012       CHA       NOH            46       47   \n",
      "\n",
      "                 home_0            home_1            home_2            home_3  \\\n",
      "0          Andrew Bynum        Lamar Odom       Luke Walton     Sasha Vujacic   \n",
      "1          Andrew Bynum        Lamar Odom       Luke Walton     Sasha Vujacic   \n",
      "2            Lamar Odom       Luke Walton     Maurice Evans      Ronny Turiaf   \n",
      "3            Lamar Odom       Luke Walton     Maurice Evans      Ronny Turiaf   \n",
      "4           Luke Walton     Maurice Evans      Ronny Turiaf      Smush Parker   \n",
      "...                 ...               ...               ...               ...   \n",
      "154527  Bismack Biyombo  Gerald Henderson      Jamario Moon      Kemba Walker   \n",
      "154528  Bismack Biyombo  Gerald Henderson      Jamario Moon      Kemba Walker   \n",
      "154529  Bismack Biyombo     Byron Mullens     Derrick Brown  Gerald Henderson   \n",
      "154530  Bismack Biyombo     Derrick Brown  Gerald Henderson      Kemba Walker   \n",
      "154531  Bismack Biyombo     Derrick Brown  Gerald Henderson      Kemba Walker   \n",
      "\n",
      "                     home_4             away_0           away_1  \\\n",
      "0              Smush Parker         Boris Diaw      Kurt Thomas   \n",
      "1              Smush Parker  Amar'e Stoudemire  Leandro Barbosa   \n",
      "2              Smush Parker  Amar'e Stoudemire  Leandro Barbosa   \n",
      "3              Smush Parker         Boris Diaw      James Jones   \n",
      "4       Vladimir Radmanovic         Boris Diaw      James Jones   \n",
      "...                     ...                ...              ...   \n",
      "154527         Tyrus Thomas    Al-Farouq Aminu      Carl Landry   \n",
      "154528         Tyrus Thomas    Al-Farouq Aminu  Greivis Vasquez   \n",
      "154529         Kemba Walker    Al-Farouq Aminu  Greivis Vasquez   \n",
      "154530         Tyrus Thomas    Al-Farouq Aminu  Greivis Vasquez   \n",
      "154531         Tyrus Thomas    Al-Farouq Aminu      Carl Landry   \n",
      "\n",
      "                 away_2           away_3           away_4  \n",
      "0             Raja Bell     Shawn Marion       Steve Nash  \n",
      "1             Raja Bell     Shawn Marion       Steve Nash  \n",
      "2             Raja Bell     Shawn Marion       Steve Nash  \n",
      "3           Kurt Thomas  Leandro Barbosa     Marcus Banks  \n",
      "4           Kurt Thomas  Leandro Barbosa     Marcus Banks  \n",
      "...                 ...              ...              ...  \n",
      "154527  Greivis Vasquez      Jason Smith  Marco Belinelli  \n",
      "154528     Gustavo Ayon      Jason Smith  Marco Belinelli  \n",
      "154529     Gustavo Ayon      Jason Smith  Marco Belinelli  \n",
      "154530     Gustavo Ayon      Jason Smith  Marco Belinelli  \n",
      "154531  Greivis Vasquez     Gustavo Ayon  Marco Belinelli  \n",
      "\n",
      "[154532 rows x 16 columns]\n",
      "(154532, 16)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\"\"\"from google.colab import drive\n",
    "\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "ds_path = '/content/drive/MyDrive/Data_Mining_Project/Datasets/'\"\"\"\n",
    "\n",
    "ds_path = 'Datasets/'\n",
    "assert os.path.exists(ds_path)\n",
    "\n",
    "features = ['outcome', 'season', 'home_team','away_team','starting_min','end_min','home_0','home_1','home_2','home_3','home_4','away_0','away_1','away_2','away_3','away_4']\n",
    "home_players_columns = ['home_0','home_1','home_2','home_3','home_4']\n",
    "away_players_columns = ['away_0','away_1','away_2','away_3','away_4']\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "# Load data from matchups-2007.csv to matchups-2012.csv and append them to df\n",
    "for i in range(2007, 2013):\n",
    "    df1 = pd.read_csv(ds_path + \"matchups-\" + str(i) + \".csv\")[features]\n",
    "    print(len(df1))\n",
    "    df = pd.concat([df, df1])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(f\"len of final df: {len(df)}\")\n",
    "print(\"first print \\n\" + str(df))\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "raw_df = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        outcome  season  home_team  away_team  starting_min  end_min  home_0  \\\n",
      "0            -1       0         12         24             0        5      41   \n",
      "1            -1       0         12         24             6        7      41   \n",
      "2             1       0         12         24             8        9     482   \n",
      "3             1       0         12         24            10       10     482   \n",
      "4            -1       0         12         24            11       11     511   \n",
      "...         ...     ...        ...        ...           ...      ...     ...   \n",
      "154527       -1       5          2         18            38       39      72   \n",
      "154528       -1       5          2         18            40       41      72   \n",
      "154529       -1       5          2         18            42       42      72   \n",
      "154530       -1       5          2         18            43       45      72   \n",
      "154531       -1       5          2         18            46       47      72   \n",
      "\n",
      "        home_1  home_2  home_3  home_4  away_0  away_1  away_2  away_3  away_4  \n",
      "0          482     511     692     715      81     474     634     710     729  \n",
      "1          482     511     692     715      26     494     634     710     729  \n",
      "2          511     554     673     715      26     494     634     710     729  \n",
      "3          511     554     673     715      81     346     474     494     528  \n",
      "4          554     673     715     785      81     346     474     494     528  \n",
      "...        ...     ...     ...     ...     ...     ...     ...     ...     ...  \n",
      "154527     290     340     453     776      13     104     303     365     527  \n",
      "154528     290     340     453     776      13     303     305     365     527  \n",
      "154529     100     216     290     453      13     303     305     365     527  \n",
      "154530     216     290     453     776      13     303     305     365     527  \n",
      "154531     216     290     453     776      13     104     303     305     527  \n",
      "\n",
      "[154532 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Label encoding for teams and players\n",
    "player_le = LabelEncoder()\n",
    "team_le = LabelEncoder()\n",
    "season_le = LabelEncoder()\n",
    "\n",
    "# Encoding players\n",
    "# Flatten the DataFrame to encode all player positions together\n",
    "player_columns = [f'home_{i}' for i in range(5)] + [f'away_{i}' for i in range(5)]\n",
    "all_players = raw_df[player_columns].values.flatten()\n",
    "\n",
    "# Fit the LabelEncoder on all player names\n",
    "player_le.fit(all_players)\n",
    "\n",
    "# Transform each player column in the DataFrame\n",
    "for col in player_columns:\n",
    "    df[col] = player_le.transform(raw_df[col])\n",
    "\n",
    "\n",
    "# Encoding teams\n",
    "df['home_team'] = team_le.fit_transform(raw_df['home_team'])\n",
    "df['away_team'] = team_le.transform(raw_df['away_team'])\n",
    "df['season'] = season_le.fit_transform(raw_df['season'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"team_season_players = {}\n",
    "\n",
    "# Process home team players\n",
    "for _, row in raw_df.iterrows():\n",
    "    # Home team\n",
    "    home_team = row['home_team']\n",
    "    season = row['season']\n",
    "    home_players = {row[f'home_{i}'] for i in range(5)}\n",
    "    \n",
    "    if home_team not in team_season_players:\n",
    "        team_season_players[home_team] = {}\n",
    "    if season not in team_season_players[home_team]:\n",
    "        team_season_players[home_team][season] = set()\n",
    "    \n",
    "    team_season_players[home_team][season].update(home_players)\n",
    "    \n",
    "    # Away team (repeating the process for the away team)\n",
    "    away_team = row['away_team']\n",
    "    away_players = {row[f'away_{i}'] for i in range(5)}\n",
    "    \n",
    "    if away_team not in team_season_players:\n",
    "        team_season_players[away_team] = {}\n",
    "    if season not in team_season_players[away_team]:\n",
    "        team_season_players[away_team][season] = set()\n",
    "    \n",
    "    team_season_players[away_team][season].update(away_players)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "dRN-oNXvbxLX"
   },
   "outputs": [],
   "source": [
    "# OTHER\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame with the player columns\n",
    "# Example columns: ['home_0', 'home_1', ..., 'away_4']\n",
    "\n",
    "\"\"\"def preprocess_data(df1):\n",
    "    # Initialize new columns\n",
    "    df = df1.copy()\n",
    "    df['target_player_name'] = None\n",
    "    df['player_names'] = None\n",
    "    \n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        # Get all player names for the row\n",
    "        players = row[['home_0', 'home_1', 'home_2', 'home_3', 'home_4', 'away_0', 'away_1', 'away_2', 'away_3', 'away_4']].tolist()\n",
    "        \n",
    "        # Randomly select one player as the target\n",
    "        target_player = np.random.choice(players)\n",
    "        \n",
    "        # Use the remaining players as the context\n",
    "        context_players = [player for player in players if player != target_player]\n",
    "        \n",
    "        # Assign to the DataFrame\n",
    "        df.at[index, 'target_player_name'] = target_player\n",
    "        df.at[index, 'player_names'] = context_players\n",
    "        \n",
    "    \n",
    "    df = df.drop(['home_0', 'home_1', 'home_2', 'home_3', 'home_4', 'away_0', 'away_1', 'away_2', 'away_3', 'away_4'], axis=1)\n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def preprocess_data_expanded(df1):\n",
    "    # Initialize a list to hold new rows\n",
    "    new_rows = []\n",
    "    \n",
    "    for index, row in df1.iterrows():\n",
    "        # Get all player names for the row\n",
    "        players = row[['home_0', 'home_1', 'home_2', 'home_3', 'home_4', 'away_0', 'away_1', 'away_2', 'away_3', 'away_4']].tolist()\n",
    "        \n",
    "        # Iterate over all players, selecting each one as the target once\n",
    "        for target_player in players:\n",
    "            # Use the remaining players as the context\n",
    "            context_players = [player for player in players if player != target_player]\n",
    "            \n",
    "            # Create a new row with this player as the target\n",
    "            new_row = row.copy()\n",
    "            new_row['target_player_name'] = target_player\n",
    "            new_row['player_names'] = context_players\n",
    "            \n",
    "            # Append the new row to the list\n",
    "            new_rows.append(new_row)\n",
    "    \n",
    "    # Create a new DataFrame from the list of new rows\n",
    "    new_df = pd.DataFrame(new_rows).reset_index(drop=True)\n",
    "    \n",
    "    # Drop the original player columns\n",
    "    new_df = new_df.drop(['home_0', 'home_1', 'home_2', 'home_3', 'home_4', 'away_0', 'away_1', 'away_2', 'away_3', 'away_4'], axis=1)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "# Apply preprocessing\n",
    "df_preprocessed = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "812\n"
     ]
    }
   ],
   "source": [
    "# Flatten the DataFrame slice into a single array of player names\n",
    "player_names_array = df[[\"home_0\", \"home_1\", \"home_2\", \"home_3\", \"home_4\", \"away_0\", \"away_1\", \"away_2\", \"away_3\", \"away_4\"]].values.flatten()\n",
    "\n",
    "# Find the unique player names in the array\n",
    "unique_player_names = np.unique(player_names_array)\n",
    "print(len(unique_player_names))\n",
    "\n",
    "\n",
    "unique_teams = np.unique(df[['home_team', 'away_team']].values.flatten())\n",
    "\n",
    "unique_seasons = np.unique(df['season'].values)\n",
    "unique_seasons = np.array([str(season) for season in unique_seasons])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        outcome  season  home_team  away_team  starting_min  end_min  \\\n",
      "0            -1       0         12         24             0        5   \n",
      "1            -1       0         12         24             6        7   \n",
      "2             1       0         12         24             8        9   \n",
      "3             1       0         12         24            10       10   \n",
      "4            -1       0         12         24            11       11   \n",
      "...         ...     ...        ...        ...           ...      ...   \n",
      "154527       -1       5          2         18            38       39   \n",
      "154528       -1       5          2         18            40       41   \n",
      "154529       -1       5          2         18            42       42   \n",
      "154530       -1       5          2         18            43       45   \n",
      "154531       -1       5          2         18            46       47   \n",
      "\n",
      "       target_player_name                                  player_names  \n",
      "0                      41  [482, 511, 692, 715, 81, 474, 634, 710, 729]  \n",
      "1                     692   [41, 482, 511, 715, 26, 494, 634, 710, 729]  \n",
      "2                     729  [482, 511, 554, 673, 715, 26, 494, 634, 710]  \n",
      "3                     482  [511, 554, 673, 715, 81, 346, 474, 494, 528]  \n",
      "4                     511  [554, 673, 715, 785, 81, 346, 474, 494, 528]  \n",
      "...                   ...                                           ...  \n",
      "154527                776   [72, 290, 340, 453, 13, 104, 303, 365, 527]  \n",
      "154528                365   [72, 290, 340, 453, 776, 13, 303, 305, 527]  \n",
      "154529                 72  [100, 216, 290, 453, 13, 303, 305, 365, 527]  \n",
      "154530                 72  [216, 290, 453, 776, 13, 303, 305, 365, 527]  \n",
      "154531                 13  [72, 216, 290, 453, 776, 104, 303, 305, 527]  \n",
      "\n",
      "[154532 rows x 8 columns]\n",
      "[41, 482, 511, 715, 26, 494, 634, 710, 729]\n",
      "812\n"
     ]
    }
   ],
   "source": [
    "# OTHER\n",
    "print(df_preprocessed)\n",
    "print(df_preprocessed.loc[1,'player_names'])\n",
    "print(len(unique_player_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        outcome  season  home_team  away_team  starting_min  end_min  \\\n",
      "120762       -1       4         16         31            13       15   \n",
      "80136        -1       2         13         18            24       24   \n",
      "104090        1       3         23         25            23       24   \n",
      "24772        -1       0         19          7            42       44   \n",
      "43933        -1       1         20          5            21       21   \n",
      "...         ...     ...        ...        ...           ...      ...   \n",
      "58268        -1       2         12         18            17       17   \n",
      "129110        1       4         11         25             0        3   \n",
      "69783         1       2          1         26            46       47   \n",
      "56845        -1       2          8         21            21       21   \n",
      "42652         1       1         29          1            46       47   \n",
      "\n",
      "       target_player_name                                   player_names  \n",
      "120762                791    [53, 413, 546, 596, 12, 330, 467, 594, 641]  \n",
      "80136                 644   [182, 306, 543, 600, 630, 57, 314, 624, 681]  \n",
      "104090                689      [22, 33, 503, 746, 34, 89, 180, 481, 546]  \n",
      "24772                 670   [115, 223, 225, 314, 352, 58, 108, 363, 742]  \n",
      "43933                 354  [256, 280, 338, 627, 224, 227, 232, 271, 391]  \n",
      "...                   ...                                            ...  \n",
      "58268                 619  [214, 482, 763, 785, 133, 198, 624, 644, 777]  \n",
      "129110                481      [65, 74, 130, 266, 682, 34, 89, 529, 595]  \n",
      "69783                 313   [281, 495, 616, 755, 76, 237, 279, 367, 720]  \n",
      "56845                 338   [49, 451, 658, 725, 223, 375, 458, 592, 679]  \n",
      "42652                 348    [36, 191, 340, 404, 473, 96, 254, 293, 755]  \n",
      "\n",
      "[123625 rows x 8 columns]\n",
      "        outcome  season  home_team  away_team  starting_min  end_min  \\\n",
      "124351       -1       4         10         23            10       10   \n",
      "11010        -1       0         22         30            42       42   \n",
      "57111        -1       2         11          8            33       33   \n",
      "129627       -1       4         11         31            24       24   \n",
      "133469       -1       5         18          6            35       36   \n",
      "...         ...     ...        ...        ...           ...      ...   \n",
      "31187         1       1         24         20             0        6   \n",
      "94735         1       3         20          7            13       16   \n",
      "11646        -1       0         11         26            46       46   \n",
      "146650       -1       5         11          8            21       21   \n",
      "15816         1       0         10         29            25       26   \n",
      "\n",
      "       target_player_name                                   player_names  \n",
      "124351                430   [178, 190, 621, 674, 772, 33, 396, 545, 746]  \n",
      "11010                 556  [244, 312, 326, 466, 763, 107, 214, 215, 552]  \n",
      "57111                 266    [65, 280, 529, 656, 43, 102, 147, 338, 725]  \n",
      "129627                307   [74, 130, 266, 580, 682, 330, 408, 414, 554]  \n",
      "133469                471      [104, 130, 303, 365, 527, 9, 34, 60, 176]  \n",
      "...                   ...                                            ...  \n",
      "31187                 280   [26, 297, 494, 710, 729, 195, 256, 338, 537]  \n",
      "94735                   9  [354, 417, 587, 801, 120, 142, 161, 363, 411]  \n",
      "11646                 751   [147, 156, 261, 708, 84, 148, 407, 558, 568]  \n",
      "146650                383    [74, 133, 457, 580, 594, 90, 240, 469, 587]  \n",
      "15816                 337   [178, 384, 570, 770, 50, 125, 419, 420, 643]  \n",
      "\n",
      "[30907 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# data split\n",
    "X_train_bu, X_test_bu = train_test_split(df_preprocessed, test_size=0.2, random_state=52)\n",
    "print(X_train_bu)\n",
    "print(X_test_bu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "\n",
    "def select_model(num):\n",
    "    global model\n",
    "    if num == 1:\n",
    "        player_input_dim = len(player_le.classes_)\n",
    "\n",
    "        player_input = Input(shape=(9,), dtype='int32', name='player_input')\n",
    "        player_embedding = Embedding(input_dim=player_input_dim + 1, output_dim=64)(player_input)\n",
    "        player_embedding_pooled = GlobalAveragePooling1D()(player_embedding)\n",
    "        \n",
    "        dense_layer = Dense(256, activation='relu')(player_embedding_pooled)\n",
    "        dense_layer = Dense(256, activation='relu')(dense_layer)\n",
    "        output_layer = Dense(player_input_dim, activation='softmax')(dense_layer)\n",
    "        \n",
    "        model = Model(inputs=player_input, outputs=output_layer)\n",
    "    elif num == 2:\n",
    "        player_input_dim = len(player_le.classes_)\n",
    "\n",
    "        player_input = Input(shape=(9,), dtype='int32', name='player_input')\n",
    "        player_embedding = Embedding(input_dim=player_input_dim + 1, output_dim=64)(player_input)\n",
    "        player_embedding_pooled = GlobalAveragePooling1D()(player_embedding)\n",
    "        \n",
    "        dense_layer = Dense(512, activation='relu')(player_embedding_pooled)\n",
    "        dense_layer = Dense(256, activation='relu')(dense_layer)\n",
    "        output_layer = Dense(player_input_dim, activation='softmax')(dense_layer)\n",
    "        \n",
    "        model = Model(inputs=player_input, outputs=output_layer)\n",
    "\n",
    "    elif num == 3:\n",
    "        player_input_dim = len(player_le.classes_)\n",
    "\n",
    "        player_input = Input(shape=(9,), dtype='int32', name='player_input')\n",
    "        player_embedding = Embedding(input_dim=player_input_dim + 1, output_dim=64)(player_input)\n",
    "        player_embedding_pooled = GlobalAveragePooling1D()(player_embedding)\n",
    "        \n",
    "        dense_layer = Dense(128, activation='relu')(player_embedding_pooled)\n",
    "        dense_layer = Dense(128, activation='relu')(dense_layer)\n",
    "        dense_layer = Dense(128, activation='relu')(dense_layer)\n",
    "        output_layer = Dense(player_input_dim, activation='softmax')(dense_layer)\n",
    "        \n",
    "        model = Model(inputs=player_input, outputs=output_layer)\n",
    "    #elif num == 2:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning rate schedule function.\"\"\"\n",
    "    initial_lr = 0.001\n",
    "    if epoch < epochs / 4:\n",
    "        return initial_lr\n",
    "    else:\n",
    "        return initial_lr * np.exp(-0.1 * epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'log_dir = \"logs23_ModelNum1/fit/\"\\nif os.path.exists(log_dir):\\n    shutil.rmtree(log_dir)\\nos.makedirs(log_dir)\\ntensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\\nlr_scheduler = LearningRateScheduler(lr_schedule)\\nselect_model(1)\\n\\nmodel.compile(optimizer=\\'adam\\', loss=\\'sparse_categorical_crossentropy\\', metrics=[\\'accuracy\\'])\\n\\n# Assuming X_train[\\'player_names\\'] and X_train[\\'target_player_name\\'] are defined correctly\\nplayer_names_padded = pad_sequences(X_train[\\'player_names\\'], maxlen=9, padding=\\'post\\', value=0)\\ntarget_player_names = tf.cast(np.array(X_train[\\'target_player_name\\'].values).astype(np.float32), dtype=tf.int32)\\n\\n\\n\\n\\n\\nmodel.fit(player_names_padded, \\n          target_player_names,\\n          batch_size=32, \\n          epochs=epochs, \\n          validation_split=0.2,\\n          verbose=False,\\n          callbacks=[tensorboard_callback, lr_scheduler])\\n\\n\\ntest_player_names_padded = pad_sequences(X_test[\\'player_names\\'], maxlen=9, padding=\\'post\\', value=0)\\ntest_target_player_names = tf.cast(np.array(X_test[\\'target_player_name\\'].values).astype(np.float32), dtype=tf.int32)\\nloss, accuracy = model.evaluate(test_player_names_padded, test_target_player_names)\\nprint(accuracy)\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only players\n",
    "from tensorflow.keras.layers import Input, Embedding, concatenate, Dropout, Dense, GlobalAveragePooling1D, Reshape, Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "import shutil\n",
    "from numpy.random import seed\n",
    "\n",
    "res_path = 'Results2/'\n",
    "def train_NN(mod_num):\n",
    "    accuracy_list = []\n",
    "    \n",
    "    for a_seed in range(100, 111):\n",
    "        np.random.seed(a_seed)\n",
    "        seed(a_seed)\n",
    "        select_model(mod_num)\n",
    "        \n",
    "        X_train, X_val = train_test_split(X_train_bu, test_size=0.2, random_state=a_seed)\n",
    "        \n",
    "        lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        player_names_padded_train = pad_sequences(X_train['player_names'], maxlen=9, padding='post', value=0)\n",
    "        target_player_names_train = tf.cast(np.array(X_train['target_player_name'].values).astype(np.float32), dtype=tf.int32)\n",
    "        player_names_padded_val = pad_sequences(X_val['player_names'], maxlen=9, padding='post', value=0)\n",
    "        target_player_names_val = tf.cast(np.array(X_val['target_player_name'].values).astype(np.float32), dtype=tf.int32)\n",
    "    \n",
    "        # Train the model\n",
    "        history = model.fit(player_names_padded_train, target_player_names_train, epochs=epochs, \n",
    "                            validation_data=(player_names_padded_val, target_player_names_val), verbose=False,\n",
    "                            callbacks=[lr_scheduler])\n",
    "\n",
    "        loss, accuracy = model.evaluate(player_names_padded_val, target_player_names_val)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Retrain and Evaluate the model\n",
    "    # Clear log directory if it exists\n",
    "    log_dir = \"logs23_ModelNum\" + str(mod_num) + \"/fit/\"\n",
    "    if os.path.exists(log_dir):\n",
    "        shutil.rmtree(log_dir)\n",
    "    os.makedirs(log_dir)\n",
    "    sm_checkpoint = tf.keras.callbacks.ModelCheckpoint(res_path + 'checkpoints/best_model_' + str(mod_num) + '.h5', \n",
    "                                \t\t\t\t\t\t\tmonitor='val_accuracy', verbose=0, \n",
    "                                \t\t\t\t\t\t\tsave_best_only=True, mode='max')\n",
    "    # Define TensorBoard callback\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    select_model(mod_num)\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    player_names_padded = pad_sequences(X_train_bu['player_names'], maxlen=9, padding='post', value=0)\n",
    "    target_player_names = tf.cast(np.array(X_train_bu['target_player_name'].values).astype(np.float32), dtype=tf.int32)\n",
    "    test_player_names_padded = pad_sequences(X_test['player_names'], maxlen=9, padding='post', value=0)\n",
    "    test_target_player_names = tf.cast(np.array(X_test['target_player_name'].values).astype(np.float32), dtype=tf.int32)\n",
    "    \n",
    "    history = model.fit(player_names_padded, target_player_names, epochs=epochs, validation_data=(test_player_names_padded, test_target_player_names), \n",
    "                        verbose=False,\n",
    "                        callbacks=[tensorboard_callback, lr_scheduler, sm_checkpoint])\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_player_names_padded, test_target_player_names)\n",
    "    \n",
    "    print(f'Test Loss: {loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    print()\n",
    "    print(\"From Cross_validation:\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy_list):.4f}, std: {np.std(accuracy_list):.4f}\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"log_dir = \"logs23_ModelNum1/fit/\"\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "os.makedirs(log_dir)\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "select_model(1)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Assuming X_train['player_names'] and X_train['target_player_name'] are defined correctly\n",
    "player_names_padded = pad_sequences(X_train['player_names'], maxlen=9, padding='post', value=0)\n",
    "target_player_names = tf.cast(np.array(X_train['target_player_name'].values).astype(np.float32), dtype=tf.int32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(player_names_padded, \n",
    "          target_player_names,\n",
    "          batch_size=32, \n",
    "          epochs=epochs, \n",
    "          validation_split=0.2,\n",
    "          verbose=False,\n",
    "          callbacks=[tensorboard_callback, lr_scheduler])\n",
    "\n",
    "\n",
    "test_player_names_padded = pad_sequences(X_test['player_names'], maxlen=9, padding='post', value=0)\n",
    "test_target_player_names = tf.cast(np.array(X_test['target_player_name'].values).astype(np.float32), dtype=tf.int32)\n",
    "loss, accuracy = model.evaluate(test_player_names_padded, test_target_player_names)\n",
    "print(accuracy)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773/773 [==============================] - 1s 1ms/step - loss: 3.6359 - accuracy: 0.2116\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.6317 - accuracy: 0.2051\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.5635 - accuracy: 0.2132\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.6535 - accuracy: 0.2110\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.6405 - accuracy: 0.2073\n",
      "773/773 [==============================] - 1s 992us/step - loss: 3.6091 - accuracy: 0.2114\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.6144 - accuracy: 0.2093\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.6116 - accuracy: 0.2116\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.5409 - accuracy: 0.2138\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.6255 - accuracy: 0.2116\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.6333 - accuracy: 0.2066\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " player_input (InputLayer)   [(None, 9)]               0         \n",
      "                                                                 \n",
      " embedding_33 (Embedding)    (None, 9, 64)             52032     \n",
      "                                                                 \n",
      " global_average_pooling1d_2  (None, 64)                0         \n",
      " 9 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 812)               208684    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 343148 (1.31 MB)\n",
      "Trainable params: 343148 (1.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966/966 [==============================] - 1s 1ms/step - loss: 3.3283 - accuracy: 0.2391\n",
      "Test Loss: 3.3283\n",
      "Test Accuracy: 0.2391\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.2102, std: 0.0027\n"
     ]
    }
   ],
   "source": [
    "train_NN(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773/773 [==============================] - 1s 1ms/step - loss: 3.5137 - accuracy: 0.2261\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.5206 - accuracy: 0.2136\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.5054 - accuracy: 0.2229\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.5642 - accuracy: 0.2125\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.5621 - accuracy: 0.2131\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.5777 - accuracy: 0.2129\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.5150 - accuracy: 0.2178\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.5221 - accuracy: 0.2136\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.5894 - accuracy: 0.2083\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.5878 - accuracy: 0.2038\n",
      "773/773 [==============================] - 1s 1ms/step - loss: 3.5286 - accuracy: 0.2140\n",
      "Model: \"model_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " player_input (InputLayer)   [(None, 9)]               0         \n",
      "                                                                 \n",
      " embedding_45 (Embedding)    (None, 9, 64)             52032     \n",
      "                                                                 \n",
      " global_average_pooling1d_4  (None, 64)                0         \n",
      " 1 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 812)               208684    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425324 (1.62 MB)\n",
      "Trainable params: 425324 (1.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "966/966 [==============================] - 1s 1ms/step - loss: 3.2559 - accuracy: 0.2416\n",
      "Test Loss: 3.2559\n",
      "Test Accuracy: 0.2416\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.2144, std: 0.0059\n"
     ]
    }
   ],
   "source": [
    "train_NN(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773/773 [==============================] - 1s 989us/step - loss: 3.8254 - accuracy: 0.1589\n",
      "773/773 [==============================] - 1s 983us/step - loss: 3.8386 - accuracy: 0.1507\n",
      "773/773 [==============================] - 1s 987us/step - loss: 3.8297 - accuracy: 0.1502\n",
      "773/773 [==============================] - 1s 964us/step - loss: 3.8208 - accuracy: 0.1541\n",
      "773/773 [==============================] - 1s 967us/step - loss: 3.8855 - accuracy: 0.1462\n",
      "773/773 [==============================] - 1s 968us/step - loss: 3.8993 - accuracy: 0.1390\n",
      "773/773 [==============================] - 1s 963us/step - loss: 3.9067 - accuracy: 0.1474\n",
      "773/773 [==============================] - 1s 962us/step - loss: 3.8815 - accuracy: 0.1483\n",
      "773/773 [==============================] - 1s 956us/step - loss: 3.8001 - accuracy: 0.1575\n",
      "773/773 [==============================] - 1s 984us/step - loss: 3.8862 - accuracy: 0.1501\n",
      "773/773 [==============================] - 1s 984us/step - loss: 3.7629 - accuracy: 0.1596\n",
      "Model: \"model_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " player_input (InputLayer)   [(None, 9)]               0         \n",
      "                                                                 \n",
      " embedding_57 (Embedding)    (None, 9, 64)             52032     \n",
      "                                                                 \n",
      " global_average_pooling1d_5  (None, 64)                0         \n",
      " 3 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 812)               104748    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 198124 (773.92 KB)\n",
      "Trainable params: 198124 (773.92 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "966/966 [==============================] - 1s 1ms/step - loss: 3.5867 - accuracy: 0.1765\n",
      "Test Loss: 3.5867\n",
      "Test Accuracy: 0.1765\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.1511, std: 0.0059\n"
     ]
    }
   ],
   "source": [
    "train_NN(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[791 543 481 ... 367 679 293]\n",
      "\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python-3.11.4\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Python-3.11.4\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Python-3.11.4\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\sevza\\AppData\\Local\\Temp\\ipykernel_14724\\474670376.py\", line 11, in <module>\n      model.fit([player_names_padded],\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\losses.py\", line 2354, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\backend.py\", line 5762, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [2592,812] and labels shape [288]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_622021]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mplayer_names_padded\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtarget_player_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m288\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python-3.11.4\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Python-3.11.4\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Python-3.11.4\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\sevza\\AppData\\Local\\Temp\\ipykernel_14724\\474670376.py\", line 11, in <module>\n      model.fit([player_names_padded],\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\losses.py\", line 2354, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\backend.py\", line 5762, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [2592,812] and labels shape [288]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_622021]"
     ]
    }
   ],
   "source": [
    "# Ensure it's padded to have a fixed length if it's not already\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\"\"\"target_player_names = tf.cast(np.array(X_train['target_player_name'].values).astype(np.float32), dtype=tf.int32)\n",
    "print()\n",
    "\n",
    "print()\n",
    "model.fit([player_names_padded], \n",
    "          target_player_names,\n",
    "          batch_size=288, \n",
    "          epochs=10, \n",
    "          validation_split=0.2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, concatenate, Dropout, Dense, GlobalAveragePooling1D, Reshape, Flatten\n",
    "\n",
    "player_input_dim = len(player_le.classes_)\n",
    "team_input_dim = len(team_le.classes_)\n",
    "season_input_dim = len(season_le.classes_)\n",
    "\n",
    "# Define input layers\n",
    "player_input = Input(shape=(9,), dtype='int32', name='player_input')\n",
    "team_input = Input(shape=(2,), dtype='int32', name='team_input')\n",
    "season_input = Input(shape=(1,), dtype='int32', name='season_input')\n",
    "\n",
    "# Embedding layers\n",
    "player_embedding = Embedding(input_dim=player_input_dim + 1, output_dim=64)(player_input)\n",
    "team_embedding = Embedding(input_dim=team_input_dim + 1, output_dim=64)(team_input)\n",
    "season_embedding = Embedding(input_dim=season_input_dim + 1, output_dim=64)(season_input)\n",
    "\n",
    "# Reshape team and season embeddings to make their shapes compatible with player_embedding for concatenation\n",
    "team_embedding_reshaped = Reshape((1, -1))(team_embedding)  # Reshape to (None, 1, 128)\n",
    "season_embedding_reshaped = Reshape((1, -1))(season_embedding)  # Reshape to (None, 1, 64)\n",
    "\n",
    "# Apply pooling or flattening to the player embeddings\n",
    "player_embedding_pooled = GlobalAveragePooling1D()(player_embedding)\n",
    "\n",
    "# Since now player_embedding_pooled is 2D (None, 64), we need to adjust team and season embeddings as well\n",
    "team_embedding_flat = Flatten()(team_embedding_reshaped)\n",
    "season_embedding_flat = Flatten()(season_embedding_reshaped)\n",
    "\n",
    "# Combine embeddings\n",
    "combined_embedding = concatenate([player_embedding_pooled, team_embedding_flat, season_embedding_flat])\n",
    "\n",
    "# Fully connected layers to process the combined embeddings\n",
    "dense_layer = Dense(128, activation='relu')(combined_embedding)\n",
    "dense_layer = Dropout(0.5)(dense_layer)  # Adding dropout for regularization\n",
    "output_layer = Dense(player_input_dim, activation='softmax')(dense_layer)  # Output layer for classification\n",
    "\n",
    "# Create and compile the model\n",
    "model = Model(inputs=[player_input, team_input, season_input], outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120762    4\n",
      "80136     2\n",
      "104090    3\n",
      "24772     0\n",
      "43933     1\n",
      "         ..\n",
      "58268     2\n",
      "129110    4\n",
      "69783     2\n",
      "56845     2\n",
      "42652     1\n",
      "Name: season, Length: 123625, dtype: int64\n",
      "[546 314 180 ... 616 725 191]\n",
      "\n",
      "[array([[ 53, 413, 596, ..., 467, 594, 641],\n",
      "       [182, 306, 543, ..., 624, 644, 681],\n",
      "       [ 22,  33, 503, ...,  89, 481, 546],\n",
      "       ...,\n",
      "       [281, 313, 495, ..., 279, 367, 720],\n",
      "       [ 49, 338, 451, ..., 458, 592, 679],\n",
      "       [ 36, 340, 404, ..., 293, 348, 755]]), <tf.Tensor: shape=(123625,), dtype=int32, numpy=array([4, 2, 3, ..., 2, 2, 1])>, <tf.Tensor: shape=(123625, 2), dtype=int32, numpy=\n",
      "array([[16, 31],\n",
      "       [13, 18],\n",
      "       [23, 25],\n",
      "       ...,\n",
      "       [ 1, 26],\n",
      "       [ 8, 21],\n",
      "       [29,  1]])>]\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/embedding_2/embedding_lookup' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python-3.11.4\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Python-3.11.4\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Python-3.11.4\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\sevza\\AppData\\Local\\Temp\\ipykernel_14724\\3939008444.py\", line 19, in <module>\n      model.fit([player_names_padded, season_tensor, team_tensor],\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 272, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model/embedding_2/embedding_lookup'\nindices[0,0] = 18 is not in [0, 7)\n\t [[{{node model/embedding_2/embedding_lookup}}]] [Op:__inference_train_function_619598]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m([player_names_padded, season_tensor, team_tensor])\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mplayer_names_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseason_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteam_tensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtarget_player_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model/embedding_2/embedding_lookup' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python-3.11.4\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Python-3.11.4\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Python-3.11.4\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\sevza\\AppData\\Local\\Temp\\ipykernel_14724\\3939008444.py\", line 19, in <module>\n      model.fit([player_names_padded, season_tensor, team_tensor],\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 272, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model/embedding_2/embedding_lookup'\nindices[0,0] = 18 is not in [0, 7)\n\t [[{{node model/embedding_2/embedding_lookup}}]] [Op:__inference_train_function_619598]"
     ]
    }
   ],
   "source": [
    "# Ensure it's padded to have a fixed length if it's not already\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "player_names_padded = pad_sequences(X_train['player_names'], maxlen=9, padding='post', value=0)\n",
    "print(X_train['season'])\n",
    "team_home = X_train['home_team']\n",
    "team_away = X_train['away_team']\n",
    "season = X_train['season']\n",
    "\n",
    "# Directly specify dtype when using np.stack to avoid type-related issues\n",
    "team_tensor = np.stack((team_home.values, team_away.values), axis=-1).astype('int32')\n",
    "\n",
    "# Use TensorFlow operations to ensure compatibility if the above doesn't resolve the issue\n",
    "team_tensor = tf.cast(team_tensor, dtype=tf.int32)\n",
    "\n",
    "season_tensor = tf.cast(X_train['season'], dtype=tf.int32)\n",
    "print(X_train['target_player_name'].values)\n",
    "target_player_names = tf.cast(np.array(X_train['target_player_name'].values).astype(np.float32), dtype=tf.int32)\n",
    "print()\n",
    "print([player_names_padded, season_tensor, team_tensor])\n",
    "print()\n",
    "model.fit([player_names_padded, season_tensor, team_tensor], \n",
    "          target_player_names,\n",
    "          batch_size=32, \n",
    "          epochs=10, \n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# OTHER\n",
    "import tensorflow_recommenders as tfrs\n",
    "from typing import Dict, Text\n",
    "\n",
    "class NBARecommendationModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, unique_player_names, unique_teams, unique_seasons):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # Player model for candidates\n",
    "        self.player_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_player_names, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_player_names) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Player embedding for query\n",
    "        self.query_player_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_player_names, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_player_names) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Season embedding\n",
    "        self.season_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_seasons, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_seasons) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Team embedding\n",
    "        self.team_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_teams, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_teams) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Query model\n",
    "        self.query_model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(64, activation='relu'),\n",
    "          tf.keras.layers.Dense(embedding_dimension),\n",
    "        ])\n",
    "\n",
    "        # Retrieval task\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=self.player_model.embeddings\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # Embedding for season, home_team, and away_team\n",
    "        season_embeddings = self.season_embedding(features[\"season\"])\n",
    "        home_team_embeddings = self.team_embedding(features[\"home_team\"])\n",
    "        away_team_embeddings = self.team_embedding(features[\"away_team\"])\n",
    "\n",
    "        # Embeddings for the 9 known players\n",
    "        player_embeddings = self.query_player_embedding(features[\"player_names\"])\n",
    "\n",
    "        # Combine all embeddings\n",
    "        combined_embeddings = tf.concat([\n",
    "            season_embeddings, home_team_embeddings, away_team_embeddings, tf.reduce_mean(player_embeddings, axis=1)\n",
    "        ], axis=1)\n",
    "\n",
    "        user_embeddings = self.query_model(combined_embeddings)\n",
    "\n",
    "        # Candidate player embeddings\n",
    "        positive_player_embeddings = self.player_model(features[\"target_player_name\"])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(user_embeddings, positive_player_embeddings)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python-3.11.4\\Lib\\site-packages\\numpy\\core\\numeric.py:2468: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# OTHER\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mNBARecommendationModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_player_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_player_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_teams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_teams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_seasons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_seasons\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdagrad(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m))\n",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m, in \u001b[0;36mNBARecommendationModel.__init__\u001b[1;34m(self, unique_player_names, unique_teams, unique_seasons)\u001b[0m\n\u001b[0;32m      9\u001b[0m embedding_dimension \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Player model for candidates\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplayer_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStringLookup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_player_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[0;32m     15\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mEmbedding(\u001b[38;5;28mlen\u001b[39m(unique_player_names) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, embedding_dimension)\n\u001b[0;32m     16\u001b[0m ])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Player embedding for query\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_player_embedding \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     20\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mStringLookup(\n\u001b[0;32m     21\u001b[0m         vocabulary\u001b[38;5;241m=\u001b[39munique_player_names, mask_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     22\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mEmbedding(\u001b[38;5;28mlen\u001b[39m(unique_player_names) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, embedding_dimension)\n\u001b[0;32m     23\u001b[0m ])\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\string_lookup.py:334\u001b[0m, in \u001b[0;36mStringLookup.__init__\u001b[1;34m(self, max_tokens, num_oov_indices, mask_token, oov_token, vocabulary, idf_weights, encoding, invert, output_mode, sparse, pad_to_max_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;241m=\u001b[39m encoding\n\u001b[1;32m--> 334\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_oov_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_oov_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43moov_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moov_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocabulary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocabulary_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43midf_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midf_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_max_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_max_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m base_preprocessing_layer\u001b[38;5;241m.\u001b[39mkeras_kpl_gauge\u001b[38;5;241m.\u001b[39mget_cell(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStringLookup\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mset(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    350\u001b[0m )\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\index_lookup.py:323\u001b[0m, in \u001b[0;36mIndexLookup.__init__\u001b[1;34m(self, max_tokens, num_oov_indices, mask_token, oov_token, vocabulary_dtype, vocabulary, idf_weights, invert, output_mode, sparse, pad_to_max_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midf_weights_const \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midf_weights\u001b[38;5;241m.\u001b[39mvalue()\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vocabulary \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midf_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;66;03m# When restoring from a keras SavedModel, the loading code will\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;66;03m# expect to find and restore a lookup_table attribute on the layer.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;66;03m# This table needs to be uninitialized as a StaticHashTable cannot\u001b[39;00m\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;66;03m# be initialized twice.\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookup_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uninitialized_lookup_table()\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\index_lookup.py:582\u001b[0m, in \u001b[0;36mIndexLookup.set_vocabulary\u001b[1;34m(self, vocabulary, idf_weights)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (new_vocab_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tokens):\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to set a vocabulary larger than the maximum vocab \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize. Passed vocab size is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, max vocab size is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    579\u001b[0m             new_vocab_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tokens\n\u001b[0;32m    580\u001b[0m         )\n\u001b[0;32m    581\u001b[0m     )\n\u001b[1;32m--> 582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookup_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lookup_table_from_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_vocabulary_size()\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_mode \u001b[38;5;241m==\u001b[39m TF_IDF \u001b[38;5;129;01mand\u001b[39;00m idf_weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\index_lookup.py:882\u001b[0m, in \u001b[0;36mIndexLookup._lookup_table_from_tokens\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m    878\u001b[0m indices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrange(token_start, token_end, dtype\u001b[38;5;241m=\u001b[39mindices_dtype)\n\u001b[0;32m    879\u001b[0m keys, values \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    880\u001b[0m     (indices, tokens) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvert \u001b[38;5;28;01melse\u001b[39;00m (tokens, indices)\n\u001b[0;32m    881\u001b[0m )\n\u001b[1;32m--> 882\u001b[0m initializer \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKeyValueTensorInitializer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_value_dtype\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mlookup\u001b[38;5;241m.\u001b[39mStaticHashTable(initializer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_value)\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\tensorflow\\python\\ops\\lookup_ops.py:548\u001b[0m, in \u001b[0;36mKeyValueTensorInitializer.__init__\u001b[1;34m(self, keys, values, key_dtype, value_dtype, name)\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[0;32m    546\u001b[0m         values, dtype\u001b[38;5;241m=\u001b[39mvalue_dtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 548\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeys\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    549\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[0;32m    550\u001b[0m       values, dtype\u001b[38;5;241m=\u001b[39mvalue_dtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey_value_init\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1443\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[0;32m   1442\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[1;32m-> 1443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[0;32m   1445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    226\u001b[0m           _add_error_prefix(\n\u001b[0;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:324\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    322\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    323\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[1;32m--> 324\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:263\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    168\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:275\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    274\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 275\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[0;32m    279\u001b[0m )\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:285\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    284\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mC:\\Python-3.11.4\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m     97\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "\"\"\"# OTHER\n",
    "model = NBARecommendationModel(unique_player_names=unique_player_names, unique_teams=unique_teams, unique_seasons=unique_seasons)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "# Fit the model\n",
    "model.fit(tf_dataset, epochs=10)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
