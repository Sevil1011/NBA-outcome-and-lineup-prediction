{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIXXcJvL2pIs"
   },
   "source": [
    "Simply applying encoding from the sklearn library leads to different codes for a player (team) when it appears in different columns.\n",
    "\n",
    "\n",
    "1. Only mapping each player (team) to a unique integer, regardless of the column is not good\n",
    "\n",
    "2. scaling: (CHATGPT:) It is not necessary to use a scaler for categorical features (players and teams) after encoding them with integer values. Scalers are typically used for numerical features to ensure that all features are on the same scale, which can be important for certain machine learning algorithms, particularly those that involve distance calculations or gradient descent optimization. Categorical features that have been encoded with integer values do not require scaling because the integers are used merely as identifiers or labels and do not carry any magnitude or order information. These encoded categorical features are typically treated as discrete variables during model training and inference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNmYZduOnd-7"
   },
   "source": [
    "Onehot encoding on the mapped integers is not also good! Since the number of features increases 10 times! Instead we change the data to present_as_home/not-present/present-as-away for each team and player for each row! In this way, we have exactly one column for all teams per row (two of them get the value of 1 and -1 and the rest are 0), and one column for each player per row (5 of them get 1, 5 get -1, and the other ones are 0).\n",
    "\n",
    "\n",
    "Also Scaling must be applied on only non-categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnb2Fl8bHUP_",
    "outputId": "7de81def-3dcf-4024-fd15-c3fae1e4713e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the matchup 2007 is 27500\n",
      "size of the matchup 2008 is 26593\n",
      "size of the matchup 2009 is 26407\n",
      "size of the matchup 2010 is 26344\n",
      "size of the matchup 2011 is 26447\n",
      "len of final df: 133291\n",
      "first print \n",
      "        outcome  season home_team away_team  starting_min        home_0  \\\n",
      "0            -1    2007       LAL       PHO             0  Andrew Bynum   \n",
      "1            -1    2007       LAL       PHO             6  Andrew Bynum   \n",
      "2             1    2007       LAL       PHO             8    Lamar Odom   \n",
      "3             1    2007       LAL       PHO            10    Lamar Odom   \n",
      "4            -1    2007       LAL       PHO            11   Luke Walton   \n",
      "...         ...     ...       ...       ...           ...           ...   \n",
      "133286       -1    2011       CHA       MIL            37    Boris Diaw   \n",
      "133287       -1    2011       CHA       MIL            38    Boris Diaw   \n",
      "133288       -1    2011       CHA       MIL            39    Boris Diaw   \n",
      "133289       -1    2011       CHA       MIL            40    Boris Diaw   \n",
      "133290       -1    2011       CHA       MIL            44    Boris Diaw   \n",
      "\n",
      "                  home_1            home_2            home_3  \\\n",
      "0             Lamar Odom       Luke Walton     Sasha Vujacic   \n",
      "1             Lamar Odom       Luke Walton     Sasha Vujacic   \n",
      "2            Luke Walton     Maurice Evans      Ronny Turiaf   \n",
      "3            Luke Walton     Maurice Evans      Ronny Turiaf   \n",
      "4          Maurice Evans      Ronny Turiaf      Smush Parker   \n",
      "...                  ...               ...               ...   \n",
      "133286        D.J. White  Gerald Henderson  Shaun Livingston   \n",
      "133287     D.J. Augustin        D.J. White  Dante Cunningham   \n",
      "133288        D.J. White  Dante Cunningham    Garrett Temple   \n",
      "133289        D.J. White  Dante Cunningham    Garrett Temple   \n",
      "133290  Dante Cunningham    Garrett Temple  Gerald Henderson   \n",
      "\n",
      "                     home_4             away_0            away_1  \\\n",
      "0              Smush Parker         Boris Diaw       Kurt Thomas   \n",
      "1              Smush Parker  Amar'e Stoudemire   Leandro Barbosa   \n",
      "2              Smush Parker  Amar'e Stoudemire   Leandro Barbosa   \n",
      "3              Smush Parker         Boris Diaw       James Jones   \n",
      "4       Vladimir Radmanovic         Boris Diaw       James Jones   \n",
      "...                     ...                ...               ...   \n",
      "133286      Stephen Jackson   Brandon Jennings    Carlos Delfino   \n",
      "133287         Matt Carroll   Brandon Jennings    Carlos Delfino   \n",
      "133288         Matt Carroll       Andrew Bogut  Brandon Jennings   \n",
      "133289         Matt Carroll       Andrew Bogut  Brandon Jennings   \n",
      "133290      Stephen Jackson       Andrew Bogut  Brandon Jennings   \n",
      "\n",
      "                away_2           away_3            away_4  \n",
      "0            Raja Bell     Shawn Marion        Steve Nash  \n",
      "1            Raja Bell     Shawn Marion        Steve Nash  \n",
      "2            Raja Bell     Shawn Marion        Steve Nash  \n",
      "3          Kurt Thomas  Leandro Barbosa      Marcus Banks  \n",
      "4          Kurt Thomas  Leandro Barbosa      Marcus Banks  \n",
      "...                ...              ...               ...  \n",
      "133286     Drew Gooden    Keyon Dooling     Larry Sanders  \n",
      "133287     Drew Gooden    Keyon Dooling     Larry Sanders  \n",
      "133288  Carlos Delfino      Drew Gooden     Keyon Dooling  \n",
      "133289  Carlos Delfino      Drew Gooden      John Salmons  \n",
      "133290  Carlos Delfino     John Salmons  Luc Mbah a Moute  \n",
      "\n",
      "[133291 rows x 15 columns]\n",
      "(133291, 15)\n",
      "print after encode teams names \n",
      "        outcome  season  starting_min        home_0            home_1  \\\n",
      "0            -1    2007             0  Andrew Bynum        Lamar Odom   \n",
      "1            -1    2007             6  Andrew Bynum        Lamar Odom   \n",
      "2             1    2007             8    Lamar Odom       Luke Walton   \n",
      "3             1    2007            10    Lamar Odom       Luke Walton   \n",
      "4            -1    2007            11   Luke Walton     Maurice Evans   \n",
      "...         ...     ...           ...           ...               ...   \n",
      "133286       -1    2011            37    Boris Diaw        D.J. White   \n",
      "133287       -1    2011            38    Boris Diaw     D.J. Augustin   \n",
      "133288       -1    2011            39    Boris Diaw        D.J. White   \n",
      "133289       -1    2011            40    Boris Diaw        D.J. White   \n",
      "133290       -1    2011            44    Boris Diaw  Dante Cunningham   \n",
      "\n",
      "                  home_2            home_3               home_4  \\\n",
      "0            Luke Walton     Sasha Vujacic         Smush Parker   \n",
      "1            Luke Walton     Sasha Vujacic         Smush Parker   \n",
      "2          Maurice Evans      Ronny Turiaf         Smush Parker   \n",
      "3          Maurice Evans      Ronny Turiaf         Smush Parker   \n",
      "4           Ronny Turiaf      Smush Parker  Vladimir Radmanovic   \n",
      "...                  ...               ...                  ...   \n",
      "133286  Gerald Henderson  Shaun Livingston      Stephen Jackson   \n",
      "133287        D.J. White  Dante Cunningham         Matt Carroll   \n",
      "133288  Dante Cunningham    Garrett Temple         Matt Carroll   \n",
      "133289  Dante Cunningham    Garrett Temple         Matt Carroll   \n",
      "133290    Garrett Temple  Gerald Henderson      Stephen Jackson   \n",
      "\n",
      "                   away_0            away_1  ... CLE MIN DEN  SEA  ATL  IND  \\\n",
      "0              Boris Diaw       Kurt Thomas  ...   0   0   0    0    0    0   \n",
      "1       Amar'e Stoudemire   Leandro Barbosa  ...   0   0   0    0    0    0   \n",
      "2       Amar'e Stoudemire   Leandro Barbosa  ...   0   0   0    0    0    0   \n",
      "3              Boris Diaw       James Jones  ...   0   0   0    0    0    0   \n",
      "4              Boris Diaw       James Jones  ...   0   0   0    0    0    0   \n",
      "...                   ...               ...  ...  ..  ..  ..  ...  ...  ...   \n",
      "133286   Brandon Jennings    Carlos Delfino  ...   0   0   0    0    0    0   \n",
      "133287   Brandon Jennings    Carlos Delfino  ...   0   0   0    0    0    0   \n",
      "133288       Andrew Bogut  Brandon Jennings  ...   0   0   0    0    0    0   \n",
      "133289       Andrew Bogut  Brandon Jennings  ...   0   0   0    0    0    0   \n",
      "133290       Andrew Bogut  Brandon Jennings  ...   0   0   0    0    0    0   \n",
      "\n",
      "        PHI  NOK  NOH  OKC  \n",
      "0         0    0    0    0  \n",
      "1         0    0    0    0  \n",
      "2         0    0    0    0  \n",
      "3         0    0    0    0  \n",
      "4         0    0    0    0  \n",
      "...     ...  ...  ...  ...  \n",
      "133286    0    0    0    0  \n",
      "133287    0    0    0    0  \n",
      "133288    0    0    0    0  \n",
      "133289    0    0    0    0  \n",
      "133290    0    0    0    0  \n",
      "\n",
      "[133291 rows x 45 columns]\n",
      "print after encode players names \n",
      "        outcome  season  starting_min  LAL  PHO  LAC  SAS  UTA  GSW  POR  ...  \\\n",
      "0            -1    2007             0    1   -1    0    0    0    0    0  ...   \n",
      "1            -1    2007             6    1   -1    0    0    0    0    0  ...   \n",
      "2             1    2007             8    1   -1    0    0    0    0    0  ...   \n",
      "3             1    2007            10    1   -1    0    0    0    0    0  ...   \n",
      "4            -1    2007            11    1   -1    0    0    0    0    0  ...   \n",
      "...         ...     ...           ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "133286       -1    2011            37    0    0    0    0    0    0    0  ...   \n",
      "133287       -1    2011            38    0    0    0    0    0    0    0  ...   \n",
      "133288       -1    2011            39    0    0    0    0    0    0    0  ...   \n",
      "133289       -1    2011            40    0    0    0    0    0    0    0  ...   \n",
      "133290       -1    2011            44    0    0    0    0    0    0    0  ...   \n",
      "\n",
      "        James Anderson  Devin Ebanks  Lance Stephenson  Gani Lawal  \\\n",
      "0                    0             0                 0           0   \n",
      "1                    0             0                 0           0   \n",
      "2                    0             0                 0           0   \n",
      "3                    0             0                 0           0   \n",
      "4                    0             0                 0           0   \n",
      "...                ...           ...               ...         ...   \n",
      "133286               0             0                 0           0   \n",
      "133287               0             0                 0           0   \n",
      "133288               0             0                 0           0   \n",
      "133289               0             0                 0           0   \n",
      "133290               0             0                 0           0   \n",
      "\n",
      "        Solomon Alabi  Craig Brackins  Dexter Pittman  Marcus Cousin  \\\n",
      "0                   0               0               0              0   \n",
      "1                   0               0               0              0   \n",
      "2                   0               0               0              0   \n",
      "3                   0               0               0              0   \n",
      "4                   0               0               0              0   \n",
      "...               ...             ...             ...            ...   \n",
      "133286              0               0               0              0   \n",
      "133287              0               0               0              0   \n",
      "133288              0               0               0              0   \n",
      "133289              0               0               0              0   \n",
      "133290              0               0               0              0   \n",
      "\n",
      "        Patrick Ewing  Pape Sy  \n",
      "0                   0        0  \n",
      "1                   0        0  \n",
      "2                   0        0  \n",
      "3                   0        0  \n",
      "4                   0        0  \n",
      "...               ...      ...  \n",
      "133286              0        0  \n",
      "133287              0        0  \n",
      "133288              0        0  \n",
      "133289              0        0  \n",
      "133290              0        0  \n",
      "\n",
      "[133291 rows x 763 columns]\n",
      "size: 101701033\n",
      "print X_train after encoding and scaling \n",
      "          season  starting_min  LAL  PHO  LAC  SAS  UTA  GSW  POR  NJN  ...  \\\n",
      "0      -1.396228     -1.895262    1   -1    0    0    0    0    0    0  ...   \n",
      "1      -1.396228     -1.433104    1   -1    0    0    0    0    0    0  ...   \n",
      "2      -1.396228     -1.279052    1   -1    0    0    0    0    0    0  ...   \n",
      "3      -1.396228     -1.124999    1   -1    0    0    0    0    0    0  ...   \n",
      "4      -1.396228     -1.047973    1   -1    0    0    0    0    0    0  ...   \n",
      "...          ...           ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "133286  1.421117      0.954712    0    0    0    0    0    0    0    0  ...   \n",
      "133287  1.421117      1.031738    0    0    0    0    0    0    0    0  ...   \n",
      "133288  1.421117      1.108765    0    0    0    0    0    0    0    0  ...   \n",
      "133289  1.421117      1.185791    0    0    0    0    0    0    0    0  ...   \n",
      "133290  1.421117      1.493896    0    0    0    0    0    0    0    0  ...   \n",
      "\n",
      "        James Anderson  Devin Ebanks  Lance Stephenson  Gani Lawal  \\\n",
      "0                    0             0                 0           0   \n",
      "1                    0             0                 0           0   \n",
      "2                    0             0                 0           0   \n",
      "3                    0             0                 0           0   \n",
      "4                    0             0                 0           0   \n",
      "...                ...           ...               ...         ...   \n",
      "133286               0             0                 0           0   \n",
      "133287               0             0                 0           0   \n",
      "133288               0             0                 0           0   \n",
      "133289               0             0                 0           0   \n",
      "133290               0             0                 0           0   \n",
      "\n",
      "        Solomon Alabi  Craig Brackins  Dexter Pittman  Marcus Cousin  \\\n",
      "0                   0               0               0              0   \n",
      "1                   0               0               0              0   \n",
      "2                   0               0               0              0   \n",
      "3                   0               0               0              0   \n",
      "4                   0               0               0              0   \n",
      "...               ...             ...             ...            ...   \n",
      "133286              0               0               0              0   \n",
      "133287              0               0               0              0   \n",
      "133288              0               0               0              0   \n",
      "133289              0               0               0              0   \n",
      "133290              0               0               0              0   \n",
      "\n",
      "        Patrick Ewing  Pape Sy  \n",
      "0                   0        0  \n",
      "1                   0        0  \n",
      "2                   0        0  \n",
      "3                   0        0  \n",
      "4                   0        0  \n",
      "...               ...      ...  \n",
      "133286              0        0  \n",
      "133287              0        0  \n",
      "133288              0        0  \n",
      "133289              0        0  \n",
      "133290              0        0  \n",
      "\n",
      "[133291 rows x 762 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "\n",
    "\"\"\"from google.colab import drive\n",
    "\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "ds_path = '/content/drive/MyDrive/Data_Mining_Project/Datasets/'\"\"\"\n",
    "\n",
    "ds_path = 'Datasets/'\n",
    "assert os.path.exists(ds_path)\n",
    "\n",
    "features = ['outcome', 'season', 'home_team','away_team','starting_min','home_0','home_1','home_2','home_3','home_4','away_0','away_1','away_2','away_3','away_4']\n",
    "home_players_columns = ['home_0','home_1','home_2','home_3','home_4']\n",
    "away_players_columns = ['away_0','away_1','away_2','away_3','away_4']\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "# Load data from matchups-2007.csv to matchups-2011.csv and append them to df\n",
    "for i in range(2007, 2012):\n",
    "    df1 = pd.read_csv(ds_path + \"matchups-\" + str(i) + \".csv\")[features]\n",
    "    print(f\"size of the matchup {i} is {len(df1)}\")\n",
    "    df = pd.concat([df, df1])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(f\"len of final df: {len(df)}\")\n",
    "print(\"first print \\n\" + str(df))\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "def encode_teams_names(df):\n",
    "    global unique_teams\n",
    "    # Get unique team names\n",
    "    unique_teams = pd.concat([df['home_team'], df['away_team']]).unique()\n",
    "    # Initialize a DataFrame with all zeros\n",
    "    encoded_df = pd.DataFrame(0, index=df.index, columns=unique_teams)\n",
    "    # Set values for home teams and away teams\n",
    "    for i in range(df.shape[0]):\n",
    "      encoded_df.loc[i, df.loc[i, 'home_team']] = 1\n",
    "      encoded_df.loc[i, df.loc[i, 'away_team']] = -1\n",
    "    #encoded_df[df['home_team']] = 1 # works incorrect\n",
    "    #encoded_df[df['away_team']] = -1 # works incorrect\n",
    "    # Concatenate the encoded team DataFrame with the original DataFrame\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    # Drop the original home_team and away_team columns\n",
    "    df = df.drop(['home_team', 'away_team'], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def encode_player_names(df):\n",
    "    global all_players\n",
    "    # Get unique player names\n",
    "    all_players = df[home_players_columns + away_players_columns].stack().unique()\n",
    "    # Initialize a DataFrame with all zeros\n",
    "    encoded_df = pd.DataFrame(0, index=df.index, columns=all_players)\n",
    "    # Set values for home team players and away team players\n",
    "    for i in range(df.shape[0]):\n",
    "      encoded_df.loc[i, df.loc[i, home_players_columns]] = 1\n",
    "      encoded_df.loc[i, df.loc[i, away_players_columns]] = -1\n",
    "    #encoded_df[df[home_players_columns]] = 1\n",
    "    #encoded_df[df[away_players_columns]] = -1\n",
    "    # Concatenate the encoded player DataFrame with the original DataFrame\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    # Drop the original player columns\n",
    "    df = df.drop(home_players_columns + away_players_columns, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = encode_teams_names(df)\n",
    "print(\"print after encode teams names \\n\" + str(df))\n",
    "#print(df[['LAL', 'PHO', 'MIL', 'CHA']])\n",
    "df = encode_player_names(df)\n",
    "print(\"print after encode players names \\n\" + str(df))\n",
    "#print(df[['Smush Parker', 'Boris Diaw', 'Matt Carroll']]) # CHECKED AND CORRECT SO FAR\n",
    "print(f\"size: {df.size}\")\n",
    "\n",
    "X_train = df.drop(\"outcome\", axis=1)\n",
    "y_train = df[\"outcome\"]\n",
    "\n",
    "\n",
    "# Feature scaling\n",
    "columns_to_scale = ['season', 'starting_min']\n",
    "scaler = StandardScaler()\n",
    "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "\n",
    "print(\"print X_train after encoding and scaling \\n\" + str(X_train))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lr4io2yox5-"
   },
   "source": [
    "So the number of features increased to 762 + 1 target.\n",
    "\n",
    "The number of training samples is 133,291. We will use 20% of them for validation during training each model.\n",
    "\n",
    "Overall, a large number of features is not good, but considering the high number of categorical features and also categories, it is the best possible way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         season  starting_min  LAL  PHO  LAC  SAS  UTA  GSW  POR  NJN  ...  \\\n",
      "0      2.125453     -1.895262    0    0    0    0    0    0    0    0  ...   \n",
      "1      2.125453     -1.433104    0    0    0    0    0    0    0    0  ...   \n",
      "2      2.125453     -1.356078    0    0    0    0    0    0    0    0  ...   \n",
      "3      2.125453     -1.202025    0    0    0    0    0    0    0    0  ...   \n",
      "4      2.125453     -1.047973    0    0    0    0    0    0    0    0  ...   \n",
      "...         ...           ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "21236  2.125453      1.031738    0    0    0    0    0    0    0    0  ...   \n",
      "21237  2.125453      1.185791    0    0    0    0    0    0    0    0  ...   \n",
      "21238  2.125453      1.339844    0    0    0    0    0    0    0    0  ...   \n",
      "21239  2.125453      1.416870    0    0    0    0    0    0    0    0  ...   \n",
      "21240  2.125453      1.647949    0    0    0    0    0    0    0    0  ...   \n",
      "\n",
      "       James Anderson  Devin Ebanks  Lance Stephenson  Gani Lawal  \\\n",
      "0                   0             0                 0           0   \n",
      "1                   0             0                 0           0   \n",
      "2                   0             0                 0           0   \n",
      "3                   0             0                 0           0   \n",
      "4                   0             0                 0           0   \n",
      "...               ...           ...               ...         ...   \n",
      "21236               0             0                 0           0   \n",
      "21237               0             0                 0           0   \n",
      "21238               0             0                 0           0   \n",
      "21239               0             0                 0           0   \n",
      "21240               0             0                 0           0   \n",
      "\n",
      "       Solomon Alabi  Craig Brackins  Dexter Pittman  Marcus Cousin  \\\n",
      "0                  0               0               0              0   \n",
      "1                  0               0               0              0   \n",
      "2                  0               0               0              0   \n",
      "3                  0               0               0              0   \n",
      "4                  0               0               0              0   \n",
      "...              ...             ...             ...            ...   \n",
      "21236              0               0               0              0   \n",
      "21237              0               0               0              0   \n",
      "21238              0               0               0              0   \n",
      "21239              0               0               0              0   \n",
      "21240              0               0               0              0   \n",
      "\n",
      "       Patrick Ewing  Pape Sy  \n",
      "0                  0        0  \n",
      "1                  0        0  \n",
      "2                  0        0  \n",
      "3                  0        0  \n",
      "4                  0        0  \n",
      "...              ...      ...  \n",
      "21236              0        0  \n",
      "21237              0        0  \n",
      "21238              0        0  \n",
      "21239              0        0  \n",
      "21240              0        0  \n",
      "\n",
      "[21241 rows x 762 columns]\n",
      "0        1\n",
      "1       -1\n",
      "2       -1\n",
      "3       -1\n",
      "4       -1\n",
      "        ..\n",
      "21236   -1\n",
      "21237   -1\n",
      "21238   -1\n",
      "21239   -1\n",
      "21240   -1\n",
      "Name: outcome, Length: 21241, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load data from matchups_2012.csv and append it to valid_df\n",
    "df_valid = pd.read_csv(ds_path + \"matchups-2012.csv\")[features]\n",
    "\n",
    "def encode_valid_df_based_on_train(valid_df):\n",
    "    encoded_df = pd.DataFrame(0, index=valid_df.index, columns=list(unique_teams) + list(all_players))\n",
    "    for i in range(valid_df.shape[0]):\n",
    "          encoded_df.loc[i, valid_df.loc[i, home_players_columns + ['home_team']]] = 1\n",
    "          encoded_df.loc[i, valid_df.loc[i, away_players_columns + ['away_team']]] = -1\n",
    "    valid_df = pd.concat([valid_df, encoded_df], axis=1)\n",
    "    # Drop the original player columns\n",
    "    valid_df = valid_df.drop(home_players_columns + away_players_columns + ['home_team', 'away_team'], axis=1)\n",
    "    valid_df = valid_df.dropna(axis='columns')\n",
    "    return valid_df\n",
    "\n",
    "\n",
    "df_valid = encode_valid_df_based_on_train(df_valid)\n",
    "X_test = df_valid.drop(\"outcome\", axis=1)\n",
    "y_test = df_valid[\"outcome\"]\n",
    "\n",
    "\n",
    "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of test samples is 21241 (and 762 columns), which are from the 2012 dataset.\n",
    "\n",
    "However, there are some new players and teams..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "Qio3EVBLshNb",
    "outputId": "f2fc7873-5087-4491-c714-f59fce7a9255"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([85405.,     0., 47886.]),\n",
       " array([-1.        , -0.33333333,  0.33333333,  1.        ]),\n",
       " <BarContainer object of 3 artists>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train, bins=3, color='blue', edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "S3loOIKIXBTI",
    "outputId": "d4848765-0316-4610-f827-f86b4be96ae1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([13454.,     0.,  7787.]),\n",
       " array([-1.        , -0.33333333,  0.33333333,  1.        ]),\n",
       " <BarContainer object of 3 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_test, bins=3, color='blue', edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = np.where(y_train == -1, 0.0, 1.0)  # Convert -1 to 0\n",
    "y_test = np.where(y_test == -1, 0.0, 1.0)    # Convert -1 to 0\n",
    "\n",
    "print(y_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1.]\n",
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "X_train_bu = X_train.copy()\n",
    "X_test_bu = X_test.copy\n",
    "y_train_bu = y_train.copy()\n",
    "y_test_bu = y_test.copy()\n",
    "\n",
    "print(y_train_bu[:3])\n",
    "print(y_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "\n",
    "def select_model(num):\n",
    "    global model\n",
    "    if num == 1:\n",
    "        model = Sequential([\n",
    "                    Dense(512, input_shape=(762,), activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(256, activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(128, activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(64, activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "                ])\n",
    "    elif num == 2:\n",
    "        model = Sequential([\n",
    "                    Dense(256, input_shape=(762,), activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(128, activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(64, activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "                ])\n",
    "    elif num == 3:\n",
    "        model = Sequential([\n",
    "                    Dense(256, input_shape=(762,), activation='relu'),\n",
    "                    BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(128, activation='relu'),\n",
    "                    BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(64, activation='relu'),\n",
    "                    BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "                ])\n",
    "\n",
    "    elif num == 4:\n",
    "        model = Sequential([\n",
    "                    Dense(128, input_shape=(762,), activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(64, activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "                ])\n",
    "    elif num == 5:\n",
    "        model = Sequential([\n",
    "                    Dense(128, input_shape=(762,), activation='relu'),\n",
    "                    BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(64, activation='relu'),\n",
    "                    BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "eyxunF1RIYk7",
    "outputId": "2d68d22d-e594-4ade-dcb3-f2735829a808",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "epochs = 20\n",
    "res_path = 'Results/'\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning rate schedule function.\"\"\"\n",
    "    initial_lr = 0.001\n",
    "    if epoch < epochs / 4:\n",
    "        return initial_lr\n",
    "    else:\n",
    "        return initial_lr * np.exp(-0.1 * epoch)\n",
    "\n",
    "\n",
    "\n",
    "def train_NN(mod_num):\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    for a_seed in range(100, 111):\n",
    "        np.random.seed(a_seed)\n",
    "        seed(a_seed)\n",
    "        select_model(mod_num)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_bu, y_train_bu, test_size=0.2, random_state=a_seed)\n",
    "        \n",
    "        lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                               tf.keras.metrics.Precision(name='precision'),\n",
    "                               tf.keras.metrics.Recall(name='recall'),\n",
    "                               tf.keras.metrics.F1Score(name='f1_score', average='macro')])\n",
    "        \n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), verbose=False,\n",
    "                            callbacks=[lr_scheduler])\n",
    "\n",
    "        loss, accuracy, precision, recall, f1_score = model.evaluate(X_val, y_val)\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1_score)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Retrain and Evaluate the model\n",
    "    # Clear log directory if it exists\n",
    "    log_dir = \"logs_ModelNum\" + str(mod_num) + \"/fit/\"\n",
    "    if os.path.exists(log_dir):\n",
    "        shutil.rmtree(log_dir)\n",
    "    os.makedirs(log_dir)\n",
    "    sm_checkpoint = tf.keras.callbacks.ModelCheckpoint(res_path + 'checkpoints/best_model_' + str(mod_num) + '.h5', \n",
    "                                \t\t\t\t\t\t\tmonitor='val_f1_score', verbose=0, \n",
    "                                \t\t\t\t\t\t\tsave_best_only=True, mode='max')\n",
    "    # Define TensorBoard callback\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    select_model(mod_num)\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                               tf.keras.metrics.Precision(name='precision'),\n",
    "                               tf.keras.metrics.Recall(name='recall'),\n",
    "                               tf.keras.metrics.F1Score(name='f1_score', average='macro')])\n",
    "\n",
    "    model.summary()\n",
    "    history = model.fit(X_train_bu, y_train_bu, epochs=epochs, validation_data=(X_test, y_test), verbose=False,\n",
    "                            callbacks=[tensorboard_callback, lr_scheduler, sm_checkpoint])\n",
    "\n",
    "    loss, accuracy, precision, recall, f1_score = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    print(f'Test Loss: {loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test Precision: {precision:.4f}')\n",
    "    print(f'Test Recall: {recall:.4f}')\n",
    "    print(f'Test F1 Score: {f1_score:.4f}')\n",
    "    print()\n",
    "    print(\"From Cross_validation:\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy_list):.4f}, std: {np.std(accuracy_list):.4f}\")\n",
    "    print(f\"Precision: {np.mean(precision_list):.4f}, std: {np.std(precision_list):.4f}\")\n",
    "    print(f\"Recall: {np.mean(recall_list):.4f}, std: {np.std(recall_list):.4f}\")\n",
    "    print(f\"F1-Score: {np.mean(f1_score_list):.4f}, std: {np.std(f1_score_list):.4f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834/834 [==============================] - 1s 2ms/step - loss: 4.9485 - accuracy: 0.5714 - precision: 0.4064 - recall: 0.3948 - f1_score: 0.5634\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 5.4243 - accuracy: 0.5745 - precision: 0.4012 - recall: 0.3850 - f1_score: 0.5529\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 5.6096 - accuracy: 0.5704 - precision: 0.4081 - recall: 0.3914 - f1_score: 0.5621\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 5.1491 - accuracy: 0.5761 - precision: 0.4071 - recall: 0.3857 - f1_score: 0.5596\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 5.2244 - accuracy: 0.5706 - precision: 0.4002 - recall: 0.3891 - f1_score: 0.5560\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 4.7845 - accuracy: 0.5700 - precision: 0.4061 - recall: 0.4119 - f1_score: 0.5613\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 5.0753 - accuracy: 0.5753 - precision: 0.4043 - recall: 0.3840 - f1_score: 0.5586\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 5.6444 - accuracy: 0.5750 - precision: 0.4030 - recall: 0.3862 - f1_score: 0.5469\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 4.8107 - accuracy: 0.5734 - precision: 0.4025 - recall: 0.3844 - f1_score: 0.5625\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 4.7902 - accuracy: 0.5726 - precision: 0.4033 - recall: 0.3938 - f1_score: 0.5643\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 4.6925 - accuracy: 0.5724 - precision: 0.4017 - recall: 0.4022 - f1_score: 0.5611\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_110 (Dense)           (None, 512)               390656    \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 563201 (2.15 MB)\n",
      "Trainable params: 563201 (2.15 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/664 [==============================] - 1s 2ms/step - loss: 5.3557 - accuracy: 0.5588 - precision: 0.4086 - recall: 0.4549 - f1_score: 0.5613\n",
      "Test Loss: 5.3557\n",
      "Test Accuracy: 0.5588\n",
      "Test Precision: 0.4086\n",
      "Test Recall: 0.4549\n",
      "Test F1 Score: 0.5613\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.5729, std: 0.0020\n",
      "Precision: 0.4040, std: 0.0025\n",
      "Recall: 0.3917, std: 0.0083\n",
      "F1-Score: 0.5590, std: 0.0050\n"
     ]
    }
   ],
   "source": [
    "train_NN(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834/834 [==============================] - 1s 2ms/step - loss: 3.3115 - accuracy: 0.5686 - precision: 0.4003 - recall: 0.3804 - f1_score: 0.5737\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.5713 - accuracy: 0.5741 - precision: 0.4050 - recall: 0.4068 - f1_score: 0.5627\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.3068 - accuracy: 0.5714 - precision: 0.4099 - recall: 0.3944 - f1_score: 0.5736\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.4675 - accuracy: 0.5757 - precision: 0.4078 - recall: 0.3917 - f1_score: 0.5672\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.5748 - accuracy: 0.5740 - precision: 0.4023 - recall: 0.3800 - f1_score: 0.5664\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.5505 - accuracy: 0.5772 - precision: 0.4088 - recall: 0.3826 - f1_score: 0.5687\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.4884 - accuracy: 0.5735 - precision: 0.4083 - recall: 0.4157 - f1_score: 0.5685\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.7717 - accuracy: 0.5701 - precision: 0.4002 - recall: 0.4003 - f1_score: 0.5634\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.8359 - accuracy: 0.5707 - precision: 0.4049 - recall: 0.4126 - f1_score: 0.5634\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 3.7559 - accuracy: 0.5775 - precision: 0.4086 - recall: 0.3918 - f1_score: 0.5672\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 3.7480 - accuracy: 0.5728 - precision: 0.4015 - recall: 0.3984 - f1_score: 0.5631\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_159 (Dense)           (None, 256)               195328    \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 236545 (924.00 KB)\n",
      "Trainable params: 236545 (924.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/664 [==============================] - 1s 2ms/step - loss: 3.7299 - accuracy: 0.5630 - precision: 0.4078 - recall: 0.4248 - f1_score: 0.5689\n",
      "Test Loss: 3.7299\n",
      "Test Accuracy: 0.5630\n",
      "Test Precision: 0.4078\n",
      "Test Recall: 0.4248\n",
      "Test F1 Score: 0.5689\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.5732, std: 0.0027\n",
      "Precision: 0.4052, std: 0.0035\n",
      "Recall: 0.3959, std: 0.0118\n",
      "F1-Score: 0.5671, std: 0.0037\n"
     ]
    }
   ],
   "source": [
    "train_NN(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834/834 [==============================] - 1s 2ms/step - loss: 1.1046 - accuracy: 0.5701 - precision: 0.4057 - recall: 0.3990 - f1_score: 0.5323\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 1.0728 - accuracy: 0.5768 - precision: 0.4002 - recall: 0.3677 - f1_score: 0.5269\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 1.0911 - accuracy: 0.5752 - precision: 0.4127 - recall: 0.3853 - f1_score: 0.5351\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 1.1036 - accuracy: 0.5767 - precision: 0.4075 - recall: 0.3840 - f1_score: 0.5300\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 1.1085 - accuracy: 0.5768 - precision: 0.4045 - recall: 0.3743 - f1_score: 0.5290\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 1.1067 - accuracy: 0.5722 - precision: 0.4033 - recall: 0.3844 - f1_score: 0.5308\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 1.1068 - accuracy: 0.5770 - precision: 0.4064 - recall: 0.3843 - f1_score: 0.5288\n",
      "834/834 [==============================] - 1s 2ms/step - loss: 1.0826 - accuracy: 0.5776 - precision: 0.4030 - recall: 0.3709 - f1_score: 0.5277\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 1.1051 - accuracy: 0.5716 - precision: 0.3959 - recall: 0.3641 - f1_score: 0.5290\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 1.0681 - accuracy: 0.5759 - precision: 0.4066 - recall: 0.3914 - f1_score: 0.5289\n",
      "834/834 [==============================] - 2s 2ms/step - loss: 1.0737 - accuracy: 0.5721 - precision: 0.3973 - recall: 0.3823 - f1_score: 0.5265\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_207 (Dense)           (None, 256)               195328    \n",
      "                                                                 \n",
      " batch_normalization_33 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_34 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_35 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_210 (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238337 (931.00 KB)\n",
      "Trainable params: 237441 (927.50 KB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/664 [==============================] - 1s 2ms/step - loss: 0.9889 - accuracy: 0.5766 - precision: 0.4174 - recall: 0.3912 - f1_score: 0.5365\n",
      "Test Loss: 0.9889\n",
      "Test Accuracy: 0.5766\n",
      "Test Precision: 0.4174\n",
      "Test Recall: 0.3912\n",
      "Test F1 Score: 0.5365\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.5747, std: 0.0026\n",
      "Precision: 0.4039, std: 0.0046\n",
      "Recall: 0.3807, std: 0.0100\n",
      "F1-Score: 0.5295, std: 0.0024\n"
     ]
    }
   ],
   "source": [
    "train_NN(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834/834 [==============================] - 1s 1ms/step - loss: 1.1066 - accuracy: 0.5756 - precision: 0.4093 - recall: 0.3842 - f1_score: 0.5799\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.0925 - accuracy: 0.5769 - precision: 0.4021 - recall: 0.3758 - f1_score: 0.5749\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.0789 - accuracy: 0.5755 - precision: 0.4123 - recall: 0.3811 - f1_score: 0.5824\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.0556 - accuracy: 0.5843 - precision: 0.4160 - recall: 0.3793 - f1_score: 0.5769\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.1340 - accuracy: 0.5742 - precision: 0.4029 - recall: 0.3815 - f1_score: 0.5780\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.0993 - accuracy: 0.5789 - precision: 0.4089 - recall: 0.3722 - f1_score: 0.5790\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.0820 - accuracy: 0.5794 - precision: 0.4093 - recall: 0.3848 - f1_score: 0.5775\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.0817 - accuracy: 0.5759 - precision: 0.3999 - recall: 0.3661 - f1_score: 0.5756\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.1032 - accuracy: 0.5761 - precision: 0.4018 - recall: 0.3660 - f1_score: 0.5763\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.0897 - accuracy: 0.5813 - precision: 0.4083 - recall: 0.3663 - f1_score: 0.5777\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.0872 - accuracy: 0.5779 - precision: 0.4004 - recall: 0.3648 - f1_score: 0.5747\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_244 (Dense)           (None, 128)               97664     \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 105985 (414.00 KB)\n",
      "Trainable params: 105985 (414.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/664 [==============================] - 1s 1ms/step - loss: 1.1117 - accuracy: 0.5710 - precision: 0.4129 - recall: 0.4034 - f1_score: 0.5744\n",
      "Test Loss: 1.1117\n",
      "Test Accuracy: 0.5710\n",
      "Test Precision: 0.4129\n",
      "Test Recall: 0.4034\n",
      "Test F1 Score: 0.5744\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.5778, std: 0.0028\n",
      "Precision: 0.4065, std: 0.0051\n",
      "Recall: 0.3747, std: 0.0075\n",
      "F1-Score: 0.5775, std: 0.0022\n"
     ]
    }
   ],
   "source": [
    "train_NN(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834/834 [==============================] - 1s 947us/step - loss: 0.9146 - accuracy: 0.5681 - precision: 0.3992 - recall: 0.3782 - f1_score: 0.5323\n",
      "834/834 [==============================] - 1s 969us/step - loss: 0.8919 - accuracy: 0.5778 - precision: 0.3999 - recall: 0.3604 - f1_score: 0.5269\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 0.8990 - accuracy: 0.5730 - precision: 0.4036 - recall: 0.3540 - f1_score: 0.5351\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 0.8892 - accuracy: 0.5807 - precision: 0.4105 - recall: 0.3740 - f1_score: 0.5299\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 0.8747 - accuracy: 0.5760 - precision: 0.4022 - recall: 0.3679 - f1_score: 0.5291\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 0.8819 - accuracy: 0.5803 - precision: 0.4096 - recall: 0.3673 - f1_score: 0.5307\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 0.8906 - accuracy: 0.5752 - precision: 0.4017 - recall: 0.3716 - f1_score: 0.5288\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 0.8705 - accuracy: 0.5805 - precision: 0.4077 - recall: 0.3765 - f1_score: 0.5277\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 0.8868 - accuracy: 0.5831 - precision: 0.4123 - recall: 0.3745 - f1_score: 0.5290\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 0.8827 - accuracy: 0.5788 - precision: 0.4108 - recall: 0.3953 - f1_score: 0.5289\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 0.8881 - accuracy: 0.5754 - precision: 0.3957 - recall: 0.3576 - f1_score: 0.5265\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 128)               97664     \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106753 (417.00 KB)\n",
      "Trainable params: 106369 (415.50 KB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/664 [==============================] - 1s 2ms/step - loss: 0.8238 - accuracy: 0.5757 - precision: 0.4118 - recall: 0.3677 - f1_score: 0.5365\n",
      "Test Loss: 0.8238\n",
      "Test Accuracy: 0.5757\n",
      "Test Precision: 0.4118\n",
      "Test Recall: 0.3677\n",
      "Test F1 Score: 0.5365\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.5772, std: 0.0040\n",
      "Precision: 0.4048, std: 0.0053\n",
      "Recall: 0.3706, std: 0.0109\n",
      "F1-Score: 0.5295, std: 0.0024\n"
     ]
    }
   ],
   "source": [
    "train_NN(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
