{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, in line-up prediction we cannot use a whole year as the test set. Since many changes have been occured (data shift), we have many new players this year and many retired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnb2Fl8bHUP_",
    "outputId": "7de81def-3dcf-4024-fd15-c3fae1e4713e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the matchup 2007 is 27500\n",
      "size of the matchup 2008 is 26593\n",
      "size of the matchup 2009 is 26407\n",
      "size of the matchup 2010 is 26344\n",
      "size of the matchup 2011 is 26447\n",
      "size of the matchup 2012 is 21241\n",
      "len of final df: 154532\n",
      "first print \n",
      "                 home_0            home_1            home_2            home_3  \\\n",
      "0          Andrew Bynum        Lamar Odom       Luke Walton     Sasha Vujacic   \n",
      "1          Andrew Bynum        Lamar Odom       Luke Walton     Sasha Vujacic   \n",
      "2            Lamar Odom       Luke Walton     Maurice Evans      Ronny Turiaf   \n",
      "3            Lamar Odom       Luke Walton     Maurice Evans      Ronny Turiaf   \n",
      "4           Luke Walton     Maurice Evans      Ronny Turiaf      Smush Parker   \n",
      "...                 ...               ...               ...               ...   \n",
      "154527  Bismack Biyombo  Gerald Henderson      Jamario Moon      Kemba Walker   \n",
      "154528  Bismack Biyombo  Gerald Henderson      Jamario Moon      Kemba Walker   \n",
      "154529  Bismack Biyombo     Byron Mullens     Derrick Brown  Gerald Henderson   \n",
      "154530  Bismack Biyombo     Derrick Brown  Gerald Henderson      Kemba Walker   \n",
      "154531  Bismack Biyombo     Derrick Brown  Gerald Henderson      Kemba Walker   \n",
      "\n",
      "                     home_4             away_0           away_1  \\\n",
      "0              Smush Parker         Boris Diaw      Kurt Thomas   \n",
      "1              Smush Parker  Amar'e Stoudemire  Leandro Barbosa   \n",
      "2              Smush Parker  Amar'e Stoudemire  Leandro Barbosa   \n",
      "3              Smush Parker         Boris Diaw      James Jones   \n",
      "4       Vladimir Radmanovic         Boris Diaw      James Jones   \n",
      "...                     ...                ...              ...   \n",
      "154527         Tyrus Thomas    Al-Farouq Aminu      Carl Landry   \n",
      "154528         Tyrus Thomas    Al-Farouq Aminu  Greivis Vasquez   \n",
      "154529         Kemba Walker    Al-Farouq Aminu  Greivis Vasquez   \n",
      "154530         Tyrus Thomas    Al-Farouq Aminu  Greivis Vasquez   \n",
      "154531         Tyrus Thomas    Al-Farouq Aminu      Carl Landry   \n",
      "\n",
      "                 away_2           away_3           away_4  \n",
      "0             Raja Bell     Shawn Marion       Steve Nash  \n",
      "1             Raja Bell     Shawn Marion       Steve Nash  \n",
      "2             Raja Bell     Shawn Marion       Steve Nash  \n",
      "3           Kurt Thomas  Leandro Barbosa     Marcus Banks  \n",
      "4           Kurt Thomas  Leandro Barbosa     Marcus Banks  \n",
      "...                 ...              ...              ...  \n",
      "154527  Greivis Vasquez      Jason Smith  Marco Belinelli  \n",
      "154528     Gustavo Ayon      Jason Smith  Marco Belinelli  \n",
      "154529     Gustavo Ayon      Jason Smith  Marco Belinelli  \n",
      "154530     Gustavo Ayon      Jason Smith  Marco Belinelli  \n",
      "154531  Greivis Vasquez     Gustavo Ayon  Marco Belinelli  \n",
      "\n",
      "[154532 rows x 10 columns]\n",
      "(154532, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\"\"\"from google.colab import drive\n",
    "\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "ds_path = '/content/drive/MyDrive/Data_Mining_Project/Datasets/'\"\"\"\n",
    "\n",
    "ds_path = 'Datasets/'\n",
    "assert os.path.exists(ds_path)\n",
    "\n",
    "home_players_columns = ['home_0','home_1','home_2','home_3','home_4']\n",
    "away_players_columns = ['away_0','away_1','away_2','away_3','away_4']\n",
    "features = home_players_columns + away_players_columns\n",
    "\n",
    "df = pd.DataFrame()\n",
    "# Load data from matchups-2007.csv to matchups-2012.csv and append them to df\n",
    "for i in range(2007, 2013):\n",
    "    df1 = pd.read_csv(ds_path + \"matchups-\" + str(i) + \".csv\")[features]\n",
    "    print(f\"size of the matchup {i} is {len(df1)}\")\n",
    "    df = pd.concat([df, df1])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(f\"len of final df: {len(df)}\")\n",
    "print(\"first print \\n\" + str(df))\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "raw_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        home_0  home_1  home_2  home_3  home_4  away_0  away_1  away_2  \\\n",
      "0           41     482     511     692     715      81     474     634   \n",
      "1           41     482     511     692     715      26     494     634   \n",
      "2          482     511     554     673     715      26     494     634   \n",
      "3          482     511     554     673     715      81     346     474   \n",
      "4          511     554     673     715     785      81     346     474   \n",
      "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "154527      72     290     340     453     776      13     104     303   \n",
      "154528      72     290     340     453     776      13     303     305   \n",
      "154529      72     100     216     290     453      13     303     305   \n",
      "154530      72     216     290     453     776      13     303     305   \n",
      "154531      72     216     290     453     776      13     104     303   \n",
      "\n",
      "        away_3  away_4  \n",
      "0          710     729  \n",
      "1          710     729  \n",
      "2          710     729  \n",
      "3          494     528  \n",
      "4          494     528  \n",
      "...        ...     ...  \n",
      "154527     365     527  \n",
      "154528     365     527  \n",
      "154529     365     527  \n",
      "154530     365     527  \n",
      "154531     305     527  \n",
      "\n",
      "[154532 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Label encoding for teams and players\n",
    "player_le = LabelEncoder()\n",
    "\n",
    "# Encoding players\n",
    "# Flatten the DataFrame to encode all player positions together\n",
    "player_columns = [f'home_{i}' for i in range(5)] + [f'away_{i}' for i in range(5)]\n",
    "all_players = raw_df[player_columns].values.flatten()\n",
    "\n",
    "# Fit the LabelEncoder on all player names\n",
    "player_le.fit(all_players)\n",
    "\n",
    "# Transform each player column in the DataFrame\n",
    "for col in player_columns:\n",
    "    df[col] = player_le.transform(raw_df[col])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dRN-oNXvbxLX"
   },
   "outputs": [],
   "source": [
    "# OTHER\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame with the player columns\n",
    "# Example columns: ['home_0', 'home_1', ..., 'away_4']\n",
    "\n",
    "\n",
    "def preprocess_data_expanded(df1):\n",
    "    # Initialize a list to hold new rows\n",
    "    new_rows = []\n",
    "    \n",
    "    for index, row in df1.iterrows():\n",
    "        # Get all player names for the row\n",
    "        players = row[features].tolist()\n",
    "        \n",
    "        # Iterate over all players, selecting each one as the target once\n",
    "        for target_player in players:\n",
    "            # Use the remaining players as the context\n",
    "            context_players = [player for player in players if player != target_player]\n",
    "            \n",
    "            # Create a new row with this player as the target\n",
    "            new_row = row.copy()\n",
    "            new_row['target_player_name'] = target_player\n",
    "            new_row['player_names'] = context_players\n",
    "            \n",
    "            # Append the new row to the list\n",
    "            new_rows.append(new_row)\n",
    "    \n",
    "    # Create a new DataFrame from the list of new rows\n",
    "    new_df = pd.DataFrame(new_rows).reset_index(drop=True)\n",
    "    \n",
    "    # Drop the original player columns\n",
    "    new_df = new_df.drop(features, axis=1)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "# Apply preprocessing\n",
    "df_preprocessed = preprocess_data_expanded(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "812\n"
     ]
    }
   ],
   "source": [
    "# Flatten the DataFrame slice into a single array of player names\n",
    "player_names_array = df[features].values.flatten()\n",
    "\n",
    "# Find the unique player names in the array\n",
    "unique_player_names = np.unique(player_names_array)\n",
    "print(len(unique_player_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         target_player_name                                  player_names\n",
      "0                        41  [482, 511, 692, 715, 81, 474, 634, 710, 729]\n",
      "1                       482   [41, 511, 692, 715, 81, 474, 634, 710, 729]\n",
      "2                       511   [41, 482, 692, 715, 81, 474, 634, 710, 729]\n",
      "3                       692   [41, 482, 511, 715, 81, 474, 634, 710, 729]\n",
      "4                       715   [41, 482, 511, 692, 81, 474, 634, 710, 729]\n",
      "...                     ...                                           ...\n",
      "1545315                  13  [72, 216, 290, 453, 776, 104, 303, 305, 527]\n",
      "1545316                 104   [72, 216, 290, 453, 776, 13, 303, 305, 527]\n",
      "1545317                 303   [72, 216, 290, 453, 776, 13, 104, 305, 527]\n",
      "1545318                 305   [72, 216, 290, 453, 776, 13, 104, 303, 527]\n",
      "1545319                 527   [72, 216, 290, 453, 776, 13, 104, 303, 305]\n",
      "\n",
      "[1545320 rows x 2 columns]\n",
      "[41, 511, 692, 715, 81, 474, 634, 710, 729]\n",
      "812\n"
     ]
    }
   ],
   "source": [
    "# OTHER\n",
    "print(df_preprocessed)\n",
    "print(df_preprocessed.loc[1,'player_names'])\n",
    "print(len(unique_player_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         target_player_name                                   player_names\n",
      "609944                  362   [55, 232, 271, 349, 178, 544, 643, 737, 770]\n",
      "787005                   33   [306, 524, 569, 600, 630, 34, 689, 746, 799]\n",
      "1092050                  26  [176, 486, 647, 801, 106, 125, 245, 401, 493]\n",
      "872852                  199       [12, 65, 444, 529, 27, 36, 55, 356, 527]\n",
      "612864                  675    [33, 503, 545, 648, 90, 356, 426, 643, 759]\n",
      "...                     ...                                            ...\n",
      "1380503                 665   [315, 366, 482, 710, 17, 101, 219, 250, 263]\n",
      "1105421                 121    [1, 152, 417, 505, 229, 365, 392, 534, 799]\n",
      "1026827                 272   [454, 459, 623, 635, 646, 40, 119, 504, 509]\n",
      "566940                   38    [93, 471, 476, 622, 49, 102, 338, 658, 673]\n",
      "1530869                 687   [63, 246, 329, 683, 691, 276, 396, 490, 597]\n",
      "\n",
      "[1236256 rows x 2 columns]\n",
      "         target_player_name                                   player_names\n",
      "724784                  761   [89, 402, 481, 727, 162, 245, 401, 538, 778]\n",
      "1157794                 619  [214, 470, 482, 558, 201, 288, 654, 750, 757]\n",
      "957702                  362  [232, 242, 366, 710, 120, 138, 653, 664, 742]\n",
      "872536                   55    [58, 288, 522, 549, 654, 36, 125, 312, 356]\n",
      "137453                  298   [61, 227, 271, 366, 280, 336, 546, 702, 761]\n",
      "...                     ...                                            ...\n",
      "1019949                 774     [11, 146, 166, 413, 460, 39, 69, 367, 456]\n",
      "1053544                 474   [87, 119, 272, 407, 130, 199, 266, 727, 761]\n",
      "595817                  195     [39, 220, 242, 487, 512, 9, 127, 354, 627]\n",
      "899818                  566    [10, 338, 399, 547, 810, 86, 244, 341, 783]\n",
      "945641                  176   [127, 195, 354, 801, 58, 448, 522, 750, 757]\n",
      "\n",
      "[309064 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# data split\n",
    "X_train_bu, X_test = train_test_split(df_preprocessed, test_size=0.2, random_state=52)\n",
    "print(X_train_bu)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "\n",
    "def select_model(num):\n",
    "    global model\n",
    "    if num == 1:\n",
    "        player_input_dim = len(player_le.classes_)\n",
    "\n",
    "        player_input = Input(shape=(9,), dtype='int32', name='player_input')\n",
    "        player_embedding = Embedding(input_dim=player_input_dim + 1, output_dim=64)(player_input)\n",
    "        player_embedding_pooled = GlobalAveragePooling1D()(player_embedding)\n",
    "        \n",
    "        dense_layer = Dense(256, activation='relu')(player_embedding_pooled)\n",
    "        dense_layer = Dense(256, activation='relu')(dense_layer)\n",
    "        output_layer = Dense(player_input_dim, activation='softmax')(dense_layer)\n",
    "        \n",
    "        \n",
    "    elif num == 2:\n",
    "        player_input_dim = len(player_le.classes_)\n",
    "\n",
    "        player_input = Input(shape=(9,), dtype='int32', name='player_input')\n",
    "        player_embedding = Embedding(input_dim=player_input_dim + 1, output_dim=64)(player_input)\n",
    "        player_embedding_pooled = GlobalAveragePooling1D()(player_embedding)\n",
    "        \n",
    "        dense_layer = Dense(512, activation='relu')(player_embedding_pooled)\n",
    "        dense_layer = Dense(256, activation='relu')(dense_layer)\n",
    "        output_layer = Dense(player_input_dim, activation='softmax')(dense_layer)\n",
    "        \n",
    "        \n",
    "\n",
    "    elif num == 3:\n",
    "        player_input_dim = len(player_le.classes_)\n",
    "\n",
    "        player_input = Input(shape=(9,), dtype='int32', name='player_input')\n",
    "        player_embedding = Embedding(input_dim=player_input_dim + 1, output_dim=64)(player_input)\n",
    "        player_embedding_pooled = GlobalAveragePooling1D()(player_embedding)\n",
    "        \n",
    "        dense_layer = Dense(128, activation='relu')(player_embedding_pooled)\n",
    "        dense_layer = Dense(128, activation='relu')(dense_layer)\n",
    "        dense_layer = Dense(128, activation='relu')(dense_layer)\n",
    "        output_layer = Dense(player_input_dim, activation='softmax')(dense_layer)\n",
    "        \n",
    "        \n",
    "    #elif num == 2:\n",
    "    model = Model(inputs=player_input, outputs=output_layer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning rate schedule function.\"\"\"\n",
    "    initial_lr = 0.001\n",
    "    if epoch < epochs / 4:\n",
    "        return initial_lr\n",
    "    else:\n",
    "        return initial_lr * np.exp(-0.1 * epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only players\n",
    "from tensorflow.keras.layers import Input, Embedding, concatenate, Dropout, Dense, GlobalAveragePooling1D, Reshape, Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "import shutil\n",
    "from numpy.random import seed\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "res_path = 'Results2/'\n",
    "def train_NN(mod_num):\n",
    "    accuracy_list = []\n",
    "    \n",
    "    for a_seed in range(100, 111):\n",
    "        np.random.seed(a_seed)\n",
    "        seed(a_seed)\n",
    "        select_model(mod_num)\n",
    "        \n",
    "        X_train, X_val = train_test_split(X_train_bu, test_size=0.2, random_state=a_seed)\n",
    "        \n",
    "        lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        player_names_padded_train = pad_sequences(X_train['player_names'], maxlen=9, padding='post', value=0)\n",
    "        target_player_names_train = tf.cast(np.array(X_train['target_player_name'].values).astype(np.float32), dtype=tf.int32)\n",
    "        player_names_padded_val = pad_sequences(X_val['player_names'], maxlen=9, padding='post', value=0)\n",
    "        target_player_names_val = tf.cast(np.array(X_val['target_player_name'].values).astype(np.float32), dtype=tf.int32)\n",
    "    \n",
    "        # Train the model\n",
    "        history = model.fit(player_names_padded_train, target_player_names_train, epochs=epochs, \n",
    "                            validation_data=(player_names_padded_val, target_player_names_val), verbose=False,\n",
    "                            callbacks=[lr_scheduler])\n",
    "\n",
    "        loss, accuracy = model.evaluate(player_names_padded_val, target_player_names_val)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Retrain and Evaluate the model\n",
    "    # Clear log directory if it exists\n",
    "    log_dir = \"logs23_ModelNum\" + str(mod_num) + \"/fit/\"\n",
    "    if os.path.exists(log_dir):\n",
    "        shutil.rmtree(log_dir)\n",
    "    os.makedirs(log_dir)\n",
    "    sm_checkpoint = tf.keras.callbacks.ModelCheckpoint(res_path + 'checkpoints/best_model_' + str(mod_num) + '.h5', \n",
    "                                \t\t\t\t\t\t\tmonitor='val_accuracy', verbose=0, \n",
    "                                \t\t\t\t\t\t\tsave_best_only=True, mode='max')\n",
    "    # Define TensorBoard callback\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    select_model(mod_num)\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    player_names_padded = pad_sequences(X_train_bu['player_names'], maxlen=9, padding='post', value=0)\n",
    "    target_player_names = tf.cast(np.array(X_train_bu['target_player_name'].values).astype(np.float32), dtype=tf.int32)\n",
    "    test_player_names_padded = pad_sequences(X_test['player_names'], maxlen=9, padding='post', value=0)\n",
    "    test_target_player_names = tf.cast(np.array(X_test['target_player_name'].values).astype(np.float32), dtype=tf.int32)\n",
    "    \n",
    "    history = model.fit(player_names_padded, target_player_names, epochs=epochs, validation_data=(test_player_names_padded, test_target_player_names), \n",
    "                        verbose=False,\n",
    "                        callbacks=[tensorboard_callback, lr_scheduler, sm_checkpoint])\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_player_names_padded, test_target_player_names)\n",
    "    \n",
    "    print(f'Test Loss: {loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    print()\n",
    "    print(\"From Cross_validation:\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy_list):.4f}, std: {np.std(accuracy_list):.4f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7727/7727 [==============================] - 10s 1ms/step - loss: 2.0857 - accuracy: 0.3946\n",
      "7727/7727 [==============================] - 10s 1ms/step - loss: 2.1376 - accuracy: 0.3876\n",
      "7727/7727 [==============================] - 10s 1ms/step - loss: 2.1081 - accuracy: 0.3905\n",
      "7727/7727 [==============================] - 10s 1ms/step - loss: 2.0871 - accuracy: 0.3957\n",
      "7727/7727 [==============================] - 11s 1ms/step - loss: 2.0935 - accuracy: 0.3929\n",
      "7727/7727 [==============================] - 9s 1ms/step - loss: 2.0959 - accuracy: 0.3952\n",
      "7727/7727 [==============================] - 10s 1ms/step - loss: 2.1091 - accuracy: 0.3921\n",
      "7727/7727 [==============================] - 9s 1ms/step - loss: 2.1034 - accuracy: 0.3947\n",
      "7727/7727 [==============================] - 9s 1ms/step - loss: 2.0702 - accuracy: 0.3963\n",
      "7727/7727 [==============================] - 10s 1ms/step - loss: 2.1017 - accuracy: 0.3898\n",
      "7727/7727 [==============================] - 11s 1ms/step - loss: 2.0549 - accuracy: 0.4031\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " player_input (InputLayer)   [(None, 9)]               0         \n",
      "                                                                 \n",
      " embedding_24 (Embedding)    (None, 9, 64)             52032     \n",
      "                                                                 \n",
      " global_average_pooling1d_2  (None, 64)                0         \n",
      " 4 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 812)               208684    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 343148 (1.31 MB)\n",
      "Trainable params: 343148 (1.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9659/9659 [==============================] - 13s 1ms/step - loss: 2.0164 - accuracy: 0.4051\n",
      "Test Loss: 2.0164\n",
      "Test Accuracy: 0.4051\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.3939, std: 0.0039\n"
     ]
    }
   ],
   "source": [
    "train_NN(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7727/7727 [==============================] - 12s 2ms/step - loss: 2.0457 - accuracy: 0.4034\n",
      "7727/7727 [==============================] - 11s 1ms/step - loss: 2.0261 - accuracy: 0.4046\n",
      "7727/7727 [==============================] - 10s 1ms/step - loss: 2.0139 - accuracy: 0.4071\n",
      "7727/7727 [==============================] - 10s 1ms/step - loss: 2.0238 - accuracy: 0.4076\n",
      "7727/7727 [==============================] - 10s 1ms/step - loss: 2.0352 - accuracy: 0.4048\n",
      "7727/7727 [==============================] - 10s 1ms/step - loss: 2.0260 - accuracy: 0.4070\n",
      "7727/7727 [==============================] - 10s 1ms/step - loss: 2.0757 - accuracy: 0.3936\n",
      "7727/7727 [==============================] - 11s 1ms/step - loss: 1.9811 - accuracy: 0.4136\n",
      "7727/7727 [==============================] - 10s 1ms/step - loss: 2.0299 - accuracy: 0.4060\n",
      "7727/7727 [==============================] - 10s 1ms/step - loss: 2.0317 - accuracy: 0.4031\n",
      "7727/7727 [==============================] - 10s 1ms/step - loss: 1.9993 - accuracy: 0.4099\n",
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " player_input (InputLayer)   [(None, 9)]               0         \n",
      "                                                                 \n",
      " embedding_36 (Embedding)    (None, 9, 64)             52032     \n",
      "                                                                 \n",
      " global_average_pooling1d_3  (None, 64)                0         \n",
      " 6 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 512)               33280     \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 812)               208684    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425324 (1.62 MB)\n",
      "Trainable params: 425324 (1.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "9659/9659 [==============================] - 21s 2ms/step - loss: 1.9052 - accuracy: 0.4265\n",
      "Test Loss: 1.9052\n",
      "Test Accuracy: 0.4265\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.4055, std: 0.0047\n"
     ]
    }
   ],
   "source": [
    "train_NN(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7727/7727 [==============================] - 11s 1ms/step - loss: 2.2285 - accuracy: 0.3441\n",
      "7727/7727 [==============================] - 8s 1ms/step - loss: 2.2851 - accuracy: 0.3272\n",
      "7727/7727 [==============================] - 8s 1ms/step - loss: 2.2745 - accuracy: 0.3381\n",
      "7727/7727 [==============================] - 8s 1ms/step - loss: 2.3276 - accuracy: 0.3252\n",
      "7727/7727 [==============================] - 8s 1ms/step - loss: 2.3204 - accuracy: 0.3288\n",
      "7727/7727 [==============================] - 8s 1ms/step - loss: 2.2978 - accuracy: 0.3332\n",
      "7727/7727 [==============================] - 8s 1ms/step - loss: 2.2469 - accuracy: 0.3386\n",
      "7727/7727 [==============================] - 8s 1ms/step - loss: 2.2428 - accuracy: 0.3404\n",
      "7727/7727 [==============================] - 8s 1ms/step - loss: 2.3243 - accuracy: 0.3249\n",
      "7727/7727 [==============================] - 9s 1ms/step - loss: 2.3148 - accuracy: 0.3277\n",
      "7727/7727 [==============================] - 8s 1ms/step - loss: 2.2350 - accuracy: 0.3427\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " player_input (InputLayer)   [(None, 9)]               0         \n",
      "                                                                 \n",
      " embedding_11 (Embedding)    (None, 9, 64)             52032     \n",
      "                                                                 \n",
      " global_average_pooling1d_1  (None, 64)                0         \n",
      " 1 (GlobalAveragePooling1D)                                      \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 812)               104748    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 198124 (773.92 KB)\n",
      "Trainable params: 198124 (773.92 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9659/9659 [==============================] - 11s 1ms/step - loss: 2.1917 - accuracy: 0.3451\n",
      "Test Loss: 2.1917\n",
      "Test Accuracy: 0.3451\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.3337, std: 0.0069\n"
     ]
    }
   ],
   "source": [
    "train_NN(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
