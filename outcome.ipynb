{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIXXcJvL2pIs"
   },
   "source": [
    "Simply applying encoding from the sklearn library leads to different codes for a player (team) when it appears in different columns.\n",
    "\n",
    "\n",
    "1. Only mapping each player (team) to a unique integer, regardless of the column is not good\n",
    "\n",
    "2. scaling: (CHATGPT:) It is not necessary to use a scaler for categorical features (players and teams) after encoding them with integer values. Scalers are typically used for numerical features to ensure that all features are on the same scale, which can be important for certain machine learning algorithms, particularly those that involve distance calculations or gradient descent optimization. Categorical features that have been encoded with integer values do not require scaling because the integers are used merely as identifiers or labels and do not carry any magnitude or order information. These encoded categorical features are typically treated as discrete variables during model training and inference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNmYZduOnd-7"
   },
   "source": [
    "Onehot encoding on the mapped integers is not also good! Since the number of features increases 10 times! Instead we change the data to present_as_home/not-present/present-as-away for each team and player for each row! In this way, we have exactly one column for all teams per row (two of them get the value of 1 and -1 and the rest are 0), and one column for each player per row (5 of them get 1, 5 get -1, and the other ones are 0).\n",
    "\n",
    "\n",
    "Also Scaling must be applied on only non-categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnb2Fl8bHUP_",
    "outputId": "7de81def-3dcf-4024-fd15-c3fae1e4713e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27500\n",
      "26593\n",
      "26407\n",
      "26344\n",
      "26447\n",
      "len of final df: 133291\n",
      "first print \n",
      "        outcome  season home_team away_team  starting_min  end_min  \\\n",
      "0            -1    2007       LAL       PHO             0        5   \n",
      "1            -1    2007       LAL       PHO             6        7   \n",
      "2             1    2007       LAL       PHO             8        9   \n",
      "3             1    2007       LAL       PHO            10       10   \n",
      "4            -1    2007       LAL       PHO            11       11   \n",
      "...         ...     ...       ...       ...           ...      ...   \n",
      "133286       -1    2011       CHA       MIL            37       37   \n",
      "133287       -1    2011       CHA       MIL            38       38   \n",
      "133288       -1    2011       CHA       MIL            39       39   \n",
      "133289       -1    2011       CHA       MIL            40       43   \n",
      "133290       -1    2011       CHA       MIL            44       47   \n",
      "\n",
      "              home_0            home_1            home_2            home_3  \\\n",
      "0       Andrew Bynum        Lamar Odom       Luke Walton     Sasha Vujacic   \n",
      "1       Andrew Bynum        Lamar Odom       Luke Walton     Sasha Vujacic   \n",
      "2         Lamar Odom       Luke Walton     Maurice Evans      Ronny Turiaf   \n",
      "3         Lamar Odom       Luke Walton     Maurice Evans      Ronny Turiaf   \n",
      "4        Luke Walton     Maurice Evans      Ronny Turiaf      Smush Parker   \n",
      "...              ...               ...               ...               ...   \n",
      "133286    Boris Diaw        D.J. White  Gerald Henderson  Shaun Livingston   \n",
      "133287    Boris Diaw     D.J. Augustin        D.J. White  Dante Cunningham   \n",
      "133288    Boris Diaw        D.J. White  Dante Cunningham    Garrett Temple   \n",
      "133289    Boris Diaw        D.J. White  Dante Cunningham    Garrett Temple   \n",
      "133290    Boris Diaw  Dante Cunningham    Garrett Temple  Gerald Henderson   \n",
      "\n",
      "                     home_4             away_0            away_1  \\\n",
      "0              Smush Parker         Boris Diaw       Kurt Thomas   \n",
      "1              Smush Parker  Amar'e Stoudemire   Leandro Barbosa   \n",
      "2              Smush Parker  Amar'e Stoudemire   Leandro Barbosa   \n",
      "3              Smush Parker         Boris Diaw       James Jones   \n",
      "4       Vladimir Radmanovic         Boris Diaw       James Jones   \n",
      "...                     ...                ...               ...   \n",
      "133286      Stephen Jackson   Brandon Jennings    Carlos Delfino   \n",
      "133287         Matt Carroll   Brandon Jennings    Carlos Delfino   \n",
      "133288         Matt Carroll       Andrew Bogut  Brandon Jennings   \n",
      "133289         Matt Carroll       Andrew Bogut  Brandon Jennings   \n",
      "133290      Stephen Jackson       Andrew Bogut  Brandon Jennings   \n",
      "\n",
      "                away_2           away_3            away_4  \n",
      "0            Raja Bell     Shawn Marion        Steve Nash  \n",
      "1            Raja Bell     Shawn Marion        Steve Nash  \n",
      "2            Raja Bell     Shawn Marion        Steve Nash  \n",
      "3          Kurt Thomas  Leandro Barbosa      Marcus Banks  \n",
      "4          Kurt Thomas  Leandro Barbosa      Marcus Banks  \n",
      "...                ...              ...               ...  \n",
      "133286     Drew Gooden    Keyon Dooling     Larry Sanders  \n",
      "133287     Drew Gooden    Keyon Dooling     Larry Sanders  \n",
      "133288  Carlos Delfino      Drew Gooden     Keyon Dooling  \n",
      "133289  Carlos Delfino      Drew Gooden      John Salmons  \n",
      "133290  Carlos Delfino     John Salmons  Luc Mbah a Moute  \n",
      "\n",
      "[133291 rows x 16 columns]\n",
      "(133291, 16)\n",
      "print after encode teams names \n",
      "        outcome  season  starting_min  end_min        home_0  \\\n",
      "0            -1    2007             0        5  Andrew Bynum   \n",
      "1            -1    2007             6        7  Andrew Bynum   \n",
      "2             1    2007             8        9    Lamar Odom   \n",
      "3             1    2007            10       10    Lamar Odom   \n",
      "4            -1    2007            11       11   Luke Walton   \n",
      "...         ...     ...           ...      ...           ...   \n",
      "133286       -1    2011            37       37    Boris Diaw   \n",
      "133287       -1    2011            38       38    Boris Diaw   \n",
      "133288       -1    2011            39       39    Boris Diaw   \n",
      "133289       -1    2011            40       43    Boris Diaw   \n",
      "133290       -1    2011            44       47    Boris Diaw   \n",
      "\n",
      "                  home_1            home_2            home_3  \\\n",
      "0             Lamar Odom       Luke Walton     Sasha Vujacic   \n",
      "1             Lamar Odom       Luke Walton     Sasha Vujacic   \n",
      "2            Luke Walton     Maurice Evans      Ronny Turiaf   \n",
      "3            Luke Walton     Maurice Evans      Ronny Turiaf   \n",
      "4          Maurice Evans      Ronny Turiaf      Smush Parker   \n",
      "...                  ...               ...               ...   \n",
      "133286        D.J. White  Gerald Henderson  Shaun Livingston   \n",
      "133287     D.J. Augustin        D.J. White  Dante Cunningham   \n",
      "133288        D.J. White  Dante Cunningham    Garrett Temple   \n",
      "133289        D.J. White  Dante Cunningham    Garrett Temple   \n",
      "133290  Dante Cunningham    Garrett Temple  Gerald Henderson   \n",
      "\n",
      "                     home_4             away_0  ... CLE MIN DEN SEA  ATL  IND  \\\n",
      "0              Smush Parker         Boris Diaw  ...   0   0   0   0    0    0   \n",
      "1              Smush Parker  Amar'e Stoudemire  ...   0   0   0   0    0    0   \n",
      "2              Smush Parker  Amar'e Stoudemire  ...   0   0   0   0    0    0   \n",
      "3              Smush Parker         Boris Diaw  ...   0   0   0   0    0    0   \n",
      "4       Vladimir Radmanovic         Boris Diaw  ...   0   0   0   0    0    0   \n",
      "...                     ...                ...  ...  ..  ..  ..  ..  ...  ...   \n",
      "133286      Stephen Jackson   Brandon Jennings  ...   0   0   0   0    0    0   \n",
      "133287         Matt Carroll   Brandon Jennings  ...   0   0   0   0    0    0   \n",
      "133288         Matt Carroll       Andrew Bogut  ...   0   0   0   0    0    0   \n",
      "133289         Matt Carroll       Andrew Bogut  ...   0   0   0   0    0    0   \n",
      "133290      Stephen Jackson       Andrew Bogut  ...   0   0   0   0    0    0   \n",
      "\n",
      "        PHI  NOK  NOH  OKC  \n",
      "0         0    0    0    0  \n",
      "1         0    0    0    0  \n",
      "2         0    0    0    0  \n",
      "3         0    0    0    0  \n",
      "4         0    0    0    0  \n",
      "...     ...  ...  ...  ...  \n",
      "133286    0    0    0    0  \n",
      "133287    0    0    0    0  \n",
      "133288    0    0    0    0  \n",
      "133289    0    0    0    0  \n",
      "133290    0    0    0    0  \n",
      "\n",
      "[133291 rows x 46 columns]\n",
      "print after encode players names \n",
      "        outcome  season  starting_min  end_min  LAL  PHO  LAC  SAS  UTA  GSW  \\\n",
      "0            -1    2007             0        5    1   -1    0    0    0    0   \n",
      "1            -1    2007             6        7    1   -1    0    0    0    0   \n",
      "2             1    2007             8        9    1   -1    0    0    0    0   \n",
      "3             1    2007            10       10    1   -1    0    0    0    0   \n",
      "4            -1    2007            11       11    1   -1    0    0    0    0   \n",
      "...         ...     ...           ...      ...  ...  ...  ...  ...  ...  ...   \n",
      "133286       -1    2011            37       37    0    0    0    0    0    0   \n",
      "133287       -1    2011            38       38    0    0    0    0    0    0   \n",
      "133288       -1    2011            39       39    0    0    0    0    0    0   \n",
      "133289       -1    2011            40       43    0    0    0    0    0    0   \n",
      "133290       -1    2011            44       47    0    0    0    0    0    0   \n",
      "\n",
      "        ...  James Anderson  Devin Ebanks  Lance Stephenson  Gani Lawal  \\\n",
      "0       ...               0             0                 0           0   \n",
      "1       ...               0             0                 0           0   \n",
      "2       ...               0             0                 0           0   \n",
      "3       ...               0             0                 0           0   \n",
      "4       ...               0             0                 0           0   \n",
      "...     ...             ...           ...               ...         ...   \n",
      "133286  ...               0             0                 0           0   \n",
      "133287  ...               0             0                 0           0   \n",
      "133288  ...               0             0                 0           0   \n",
      "133289  ...               0             0                 0           0   \n",
      "133290  ...               0             0                 0           0   \n",
      "\n",
      "        Solomon Alabi  Craig Brackins  Dexter Pittman  Marcus Cousin  \\\n",
      "0                   0               0               0              0   \n",
      "1                   0               0               0              0   \n",
      "2                   0               0               0              0   \n",
      "3                   0               0               0              0   \n",
      "4                   0               0               0              0   \n",
      "...               ...             ...             ...            ...   \n",
      "133286              0               0               0              0   \n",
      "133287              0               0               0              0   \n",
      "133288              0               0               0              0   \n",
      "133289              0               0               0              0   \n",
      "133290              0               0               0              0   \n",
      "\n",
      "        Patrick Ewing  Pape Sy  \n",
      "0                   0        0  \n",
      "1                   0        0  \n",
      "2                   0        0  \n",
      "3                   0        0  \n",
      "4                   0        0  \n",
      "...               ...      ...  \n",
      "133286              0        0  \n",
      "133287              0        0  \n",
      "133288              0        0  \n",
      "133289              0        0  \n",
      "133290              0        0  \n",
      "\n",
      "[133291 rows x 764 columns]\n",
      "size: 101834324\n",
      "print X_train after encoding and scaling \n",
      "          season  starting_min   end_min  LAL  PHO  LAC  SAS  UTA  GSW  POR  \\\n",
      "0      -1.396228     -1.895262 -1.641644    1   -1    0    0    0    0    0   \n",
      "1      -1.396228     -1.433104 -1.483906    1   -1    0    0    0    0    0   \n",
      "2      -1.396228     -1.279052 -1.326169    1   -1    0    0    0    0    0   \n",
      "3      -1.396228     -1.124999 -1.247301    1   -1    0    0    0    0    0   \n",
      "4      -1.396228     -1.047973 -1.168432    1   -1    0    0    0    0    0   \n",
      "...          ...           ...       ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "133286  1.421117      0.954712  0.882152    0    0    0    0    0    0    0   \n",
      "133287  1.421117      1.031738  0.961021    0    0    0    0    0    0    0   \n",
      "133288  1.421117      1.108765  1.039889    0    0    0    0    0    0    0   \n",
      "133289  1.421117      1.185791  1.355364    0    0    0    0    0    0    0   \n",
      "133290  1.421117      1.493896  1.670838    0    0    0    0    0    0    0   \n",
      "\n",
      "        ...  James Anderson  Devin Ebanks  Lance Stephenson  Gani Lawal  \\\n",
      "0       ...               0             0                 0           0   \n",
      "1       ...               0             0                 0           0   \n",
      "2       ...               0             0                 0           0   \n",
      "3       ...               0             0                 0           0   \n",
      "4       ...               0             0                 0           0   \n",
      "...     ...             ...           ...               ...         ...   \n",
      "133286  ...               0             0                 0           0   \n",
      "133287  ...               0             0                 0           0   \n",
      "133288  ...               0             0                 0           0   \n",
      "133289  ...               0             0                 0           0   \n",
      "133290  ...               0             0                 0           0   \n",
      "\n",
      "        Solomon Alabi  Craig Brackins  Dexter Pittman  Marcus Cousin  \\\n",
      "0                   0               0               0              0   \n",
      "1                   0               0               0              0   \n",
      "2                   0               0               0              0   \n",
      "3                   0               0               0              0   \n",
      "4                   0               0               0              0   \n",
      "...               ...             ...             ...            ...   \n",
      "133286              0               0               0              0   \n",
      "133287              0               0               0              0   \n",
      "133288              0               0               0              0   \n",
      "133289              0               0               0              0   \n",
      "133290              0               0               0              0   \n",
      "\n",
      "        Patrick Ewing  Pape Sy  \n",
      "0                   0        0  \n",
      "1                   0        0  \n",
      "2                   0        0  \n",
      "3                   0        0  \n",
      "4                   0        0  \n",
      "...               ...      ...  \n",
      "133286              0        0  \n",
      "133287              0        0  \n",
      "133288              0        0  \n",
      "133289              0        0  \n",
      "133290              0        0  \n",
      "\n",
      "[133291 rows x 763 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\"\"\"from google.colab import drive\n",
    "\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "ds_path = '/content/drive/MyDrive/Data_Mining_Project/Datasets/'\"\"\"\n",
    "\n",
    "ds_path = 'Datasets/'\n",
    "assert os.path.exists(ds_path)\n",
    "\n",
    "features = ['outcome', 'season', 'home_team','away_team','starting_min','end_min','home_0','home_1','home_2','home_3','home_4','away_0','away_1','away_2','away_3','away_4']\n",
    "home_players_columns = ['home_0','home_1','home_2','home_3','home_4']\n",
    "away_players_columns = ['away_0','away_1','away_2','away_3','away_4']\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "# Load data from matchups-2007.csv to matchups-2011.csv and append them to df\n",
    "for i in range(2007, 2012):\n",
    "    df1 = pd.read_csv(ds_path + \"matchups-\" + str(i) + \".csv\")[features]\n",
    "    print(len(df1))\n",
    "    df = pd.concat([df, df1])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(f\"len of final df: {len(df)}\")\n",
    "print(\"first print \\n\" + str(df))\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "def encode_teams_names(df):\n",
    "    global unique_teams\n",
    "    # Get unique team names\n",
    "    unique_teams = pd.concat([df['home_team'], df['away_team']]).unique()\n",
    "    # Initialize a DataFrame with all zeros\n",
    "    encoded_df = pd.DataFrame(0, index=df.index, columns=unique_teams)\n",
    "    # Set values for home teams and away teams\n",
    "    for i in range(df.shape[0]):\n",
    "      encoded_df.loc[i, df.loc[i, 'home_team']] = 1\n",
    "      encoded_df.loc[i, df.loc[i, 'away_team']] = -1\n",
    "    #encoded_df[df['home_team']] = 1 # works incorrect\n",
    "    #encoded_df[df['away_team']] = -1 # works incorrect\n",
    "    # Concatenate the encoded team DataFrame with the original DataFrame\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    # Drop the original home_team and away_team columns\n",
    "    df = df.drop(['home_team', 'away_team'], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def encode_player_names(df):\n",
    "    global all_players\n",
    "    # Get unique player names\n",
    "    all_players = df[home_players_columns + away_players_columns].stack().unique()\n",
    "    # Initialize a DataFrame with all zeros\n",
    "    encoded_df = pd.DataFrame(0, index=df.index, columns=all_players)\n",
    "    # Set values for home team players and away team players\n",
    "    for i in range(df.shape[0]):\n",
    "      encoded_df.loc[i, df.loc[i, home_players_columns]] = 1\n",
    "      encoded_df.loc[i, df.loc[i, away_players_columns]] = -1\n",
    "    #encoded_df[df[home_players_columns]] = 1\n",
    "    #encoded_df[df[away_players_columns]] = -1\n",
    "    # Concatenate the encoded player DataFrame with the original DataFrame\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    # Drop the original player columns\n",
    "    df = df.drop(home_players_columns + away_players_columns, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = encode_teams_names(df)\n",
    "print(\"print after encode teams names \\n\" + str(df))\n",
    "#print(df[['LAL', 'PHO', 'MIL', 'CHA']])\n",
    "df = encode_player_names(df)\n",
    "print(\"print after encode players names \\n\" + str(df))\n",
    "#print(df[['Smush Parker', 'Boris Diaw', 'Matt Carroll']]) # CHECKED AND CORRECT SO FAR\n",
    "print(f\"size: {df.size}\")\n",
    "\n",
    "X_train = df.drop(\"outcome\", axis=1)\n",
    "y_train = df[\"outcome\"]\n",
    "\n",
    "\n",
    "# Feature scaling\n",
    "columns_to_scale = ['season', 'starting_min', 'end_min']\n",
    "scaler = StandardScaler()\n",
    "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "\n",
    "print(\"print X_train after encoding and scaling \\n\" + str(X_train))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lr4io2yox5-"
   },
   "source": [
    "So the number of features increased to 763 + 1 target.\n",
    "\n",
    "The number of training samples is 133,291. We will use 20% of them for validation during training each model.\n",
    "\n",
    "Overall, a large number of features is not good, but considering the high number of categorical features and also categories, it is the best possible way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         season  starting_min   end_min  LAL  PHO  LAC  SAS  UTA  GSW  POR  \\\n",
      "0      2.125453     -1.895262 -1.641644    0    0    0    0    0    0    0   \n",
      "1      2.125453     -1.433104 -1.562775    0    0    0    0    0    0    0   \n",
      "2      2.125453     -1.356078 -1.405038    0    0    0    0    0    0    0   \n",
      "3      2.125453     -1.202025 -1.247301    0    0    0    0    0    0    0   \n",
      "4      2.125453     -1.047973 -1.168432    0    0    0    0    0    0    0   \n",
      "...         ...           ...       ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "21236  2.125453      1.031738  1.039889    0    0    0    0    0    0    0   \n",
      "21237  2.125453      1.185791  1.197626    0    0    0    0    0    0    0   \n",
      "21238  2.125453      1.339844  1.276495    0    0    0    0    0    0    0   \n",
      "21239  2.125453      1.416870  1.513101    0    0    0    0    0    0    0   \n",
      "21240  2.125453      1.647949  1.670838    0    0    0    0    0    0    0   \n",
      "\n",
      "       ...  James Anderson  Devin Ebanks  Lance Stephenson  Gani Lawal  \\\n",
      "0      ...               0             0                 0           0   \n",
      "1      ...               0             0                 0           0   \n",
      "2      ...               0             0                 0           0   \n",
      "3      ...               0             0                 0           0   \n",
      "4      ...               0             0                 0           0   \n",
      "...    ...             ...           ...               ...         ...   \n",
      "21236  ...               0             0                 0           0   \n",
      "21237  ...               0             0                 0           0   \n",
      "21238  ...               0             0                 0           0   \n",
      "21239  ...               0             0                 0           0   \n",
      "21240  ...               0             0                 0           0   \n",
      "\n",
      "       Solomon Alabi  Craig Brackins  Dexter Pittman  Marcus Cousin  \\\n",
      "0                  0               0               0              0   \n",
      "1                  0               0               0              0   \n",
      "2                  0               0               0              0   \n",
      "3                  0               0               0              0   \n",
      "4                  0               0               0              0   \n",
      "...              ...             ...             ...            ...   \n",
      "21236              0               0               0              0   \n",
      "21237              0               0               0              0   \n",
      "21238              0               0               0              0   \n",
      "21239              0               0               0              0   \n",
      "21240              0               0               0              0   \n",
      "\n",
      "       Patrick Ewing  Pape Sy  \n",
      "0                  0        0  \n",
      "1                  0        0  \n",
      "2                  0        0  \n",
      "3                  0        0  \n",
      "4                  0        0  \n",
      "...              ...      ...  \n",
      "21236              0        0  \n",
      "21237              0        0  \n",
      "21238              0        0  \n",
      "21239              0        0  \n",
      "21240              0        0  \n",
      "\n",
      "[21241 rows x 763 columns]\n",
      "0        1\n",
      "1       -1\n",
      "2       -1\n",
      "3       -1\n",
      "4       -1\n",
      "        ..\n",
      "21236   -1\n",
      "21237   -1\n",
      "21238   -1\n",
      "21239   -1\n",
      "21240   -1\n",
      "Name: outcome, Length: 21241, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load data from matchups_2012.csv and append it to df\n",
    "df_valid = pd.read_csv(ds_path + \"matchups-2012.csv\")[features]\n",
    "\n",
    "def encode_valid_df_based_on_train(valid_df):\n",
    "    encoded_df = pd.DataFrame(0, index=valid_df.index, columns=list(unique_teams) + list(all_players))\n",
    "    for i in range(valid_df.shape[0]):\n",
    "          encoded_df.loc[i, valid_df.loc[i, home_players_columns + ['home_team']]] = 1\n",
    "          encoded_df.loc[i, valid_df.loc[i, away_players_columns + ['away_team']]] = -1\n",
    "    valid_df = pd.concat([valid_df, encoded_df], axis=1)\n",
    "    # Drop the original player columns\n",
    "    valid_df = valid_df.drop(home_players_columns + away_players_columns + ['home_team', 'away_team'], axis=1)\n",
    "    valid_df = valid_df.dropna(axis='columns')\n",
    "    return valid_df\n",
    "\n",
    "\n",
    "df_valid = encode_valid_df_based_on_train(df_valid)\n",
    "X_test = df_valid.drop(\"outcome\", axis=1)\n",
    "y_test = df_valid[\"outcome\"]\n",
    "\n",
    "\n",
    "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of test samples is 21241 (and 763 columns), which are from the 2012 dataset.\n",
    "\n",
    "However, there are some new players and teams..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "Qio3EVBLshNb",
    "outputId": "f2fc7873-5087-4491-c714-f59fce7a9255"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([85405.,     0., 47886.]),\n",
       " array([-1.        , -0.33333333,  0.33333333,  1.        ]),\n",
       " <BarContainer object of 3 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train, bins=3, color='blue', edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "S3loOIKIXBTI",
    "outputId": "d4848765-0316-4610-f827-f86b4be96ae1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([13454.,     0.,  7787.]),\n",
       " array([-1.        , -0.33333333,  0.33333333,  1.        ]),\n",
       " <BarContainer object of 3 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_test, bins=3, color='blue', edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0t8YN_LOXGDp",
    "outputId": "e11e8fbe-b03f-4c34-d580-a251a0413630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** KNeighborsClassifier(n_neighbors=3) *****************\n",
      "Accuracy: 0.5773\n",
      "Precision: 0.3832\n",
      "Recall: 0.3316\n",
      "F1-score: 0.3556\n",
      "Confusion Matrix:\n",
      "[[12280  5004]\n",
      " [ 6266  3109]]\n",
      "*************** SVC(class_weight='balanced') *****************\n",
      "Accuracy: 0.5463\n",
      "Precision: 0.3996\n",
      "Recall: 0.5777\n",
      "F1-score: 0.4725\n",
      "Confusion Matrix:\n",
      "[[9148 8136]\n",
      " [3959 5416]]\n",
      "*************** GaussianNB() *****************\n",
      "Accuracy: 0.6483\n",
      "Precision: 0.4167\n",
      "Recall: 0.0005\n",
      "F1-score: 0.0011\n",
      "Confusion Matrix:\n",
      "[[17277     7]\n",
      " [ 9370     5]]\n"
     ]
    }
   ],
   "source": [
    "# OLD: without cross_validation - not good\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "list_of_models = [KNeighborsClassifier(n_neighbors=3), SVC(class_weight='balanced'), GaussianNB()]\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-score', 'CM'])\n",
    "for model in list_of_models:\n",
    "  print(f\"*************** {model} *****************\")\n",
    "  model.fit(X_train, y_train)\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  # Evaluate model\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  precision = precision_score(y_test, y_pred)\n",
    "  recall = recall_score(y_test, y_pred)\n",
    "  f1 = f1_score(y_test, y_pred)\n",
    "  print(f\"Accuracy: {accuracy:.4f}\")\n",
    "  print(f\"Precision: {precision:.4f}\")\n",
    "  print(f\"Recall: {recall:.4f}\")\n",
    "  print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "  from sklearn.metrics import confusion_matrix\n",
    "\n",
    "  conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "  print(\"Confusion Matrix:\")\n",
    "  print(conf_matrix)\n",
    "  results_df = results_df.append({'Model': str(model), 'Accuracy': accuracy:.4f,\n",
    "                                  \"Precision\": precision:.4f, \"Recall\": recall:.4f,\n",
    "                                  \"F1-score\": f1:.4f,\n",
    "                                  \"CM\": conf_matrix}, ignore_index=True)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('model_results.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qozrBY-uI2VV",
    "outputId": "62f346dd-29c7-466c-d4b1-a4698ccbb366"
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GZ4b1AQuoPQU",
    "outputId": "aa0cf4b9-432d-4c30-9fe3-a4ec032e71b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** KNeighborsClassifier(n_neighbors=3) *****************\n",
      "Accuracy: 0.5795\n",
      "Precision: 0.5376\n",
      "Recall: 0.5355\n",
      "F1-score: 0.5355\n",
      "*************** GaussianNB() *****************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sevza\\AppData\\Local\\Temp\\ipykernel_33784\\3265400033.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{'Model': str(model), 'Test Accuracy': round(accuracy, 4),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4542\n",
      "Precision: 0.5455\n",
      "Recall: 0.5329\n",
      "F1-score: 0.4412\n",
      "*************** LogisticRegression(class_weight='balanced') *****************\n",
      "Accuracy: 0.5642\n",
      "Precision: 0.5682\n",
      "Recall: 0.5733\n",
      "F1-score: 0.5580\n",
      "*************** RandomForestClassifier(class_weight='balanced') *****************\n",
      "Accuracy: 0.6229\n",
      "Precision: 0.5512\n",
      "Recall: 0.5236\n",
      "F1-score: 0.4890\n",
      "*************** GradientBoostingClassifier() *****************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sevza\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6333\n",
      "Precision: 0.5494\n",
      "Recall: 0.5004\n",
      "F1-score: 0.3902\n",
      "*************** LGBMClassifier() *****************\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 38308, number of negative: 68324\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2070\n",
      "[LightGBM] [Info] Number of data points in the train set: 106632, number of used features: 659\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359254 -> initscore=-0.578602\n",
      "[LightGBM] [Info] Start training from score -0.578602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sevza\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 38309, number of negative: 68324\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2195\n",
      "[LightGBM] [Info] Number of data points in the train set: 106633, number of used features: 701\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359260 -> initscore=-0.578576\n",
      "[LightGBM] [Info] Start training from score -0.578576\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 38309, number of negative: 68324\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2210\n",
      "[LightGBM] [Info] Number of data points in the train set: 106633, number of used features: 706\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359260 -> initscore=-0.578576\n",
      "[LightGBM] [Info] Start training from score -0.578576\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 38309, number of negative: 68324\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2217\n",
      "[LightGBM] [Info] Number of data points in the train set: 106633, number of used features: 708\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359260 -> initscore=-0.578576\n",
      "[LightGBM] [Info] Start training from score -0.578576\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 38309, number of negative: 68324\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2061\n",
      "[LightGBM] [Info] Number of data points in the train set: 106633, number of used features: 656\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359260 -> initscore=-0.578576\n",
      "[LightGBM] [Info] Start training from score -0.578576\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 47886, number of negative: 85405\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2247\n",
      "[LightGBM] [Info] Number of data points in the train set: 133291, number of used features: 718\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359259 -> initscore=-0.578581\n",
      "[LightGBM] [Info] Start training from score -0.578581\n",
      "Accuracy: 0.6340\n",
      "Precision: 0.5789\n",
      "Recall: 0.5042\n",
      "F1-score: 0.4045\n",
      "*************** <catboost.core.CatBoostClassifier object at 0x000001A3844A1490> *****************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sevza\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6338\n",
      "Precision: 0.5722\n",
      "Recall: 0.5113\n",
      "F1-score: 0.4324\n"
     ]
    }
   ],
   "source": [
    "# DO NOT TOUCH\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "list_of_models = [KNeighborsClassifier(n_neighbors=3),\n",
    "                  GaussianNB(),\n",
    "                  LogisticRegression(class_weight='balanced'),\n",
    "                  RandomForestClassifier(class_weight='balanced'),\n",
    "                  GradientBoostingClassifier(),\n",
    "                  #XGBClassifier(),\n",
    "                  LGBMClassifier(),\n",
    "                  CatBoostClassifier(verbose=False),\n",
    "                  #SVC(class_weight='balanced')\n",
    "                 ]\n",
    "results_df = pd.DataFrame(columns=['Model', 'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1-score', 'Mean_Accuracy', 'Std_Accuracy', 'Mean_Precision', 'Std_Precision', 'Mean_Recall', 'Std_Recall', 'Mean_F1-score', 'Std_F1-score'])\n",
    "\n",
    "for model in list_of_models:\n",
    "    print(f\"*************** {model} *****************\")\n",
    "    cv_results = cross_validate(model, X_train, y_train, cv=5, scoring=['f1', 'precision', 'recall', 'accuracy'])\n",
    "    y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "    # Evaluate model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([{'Model': str(model), 'Test Accuracy': round(accuracy, 4),\n",
    "                                    \"Test Precision\": round(precision, 4), \"Test Recall\": round(recall, 4),\n",
    "                                    \"Test F1-score\": round(f1, 4),\n",
    "                                    \"Mean_Accuracy\": round(cv_results['test_accuracy'].mean(), 4),\n",
    "                                    \"Std_Accuracy\": round(cv_results['test_accuracy'].std(), 4),\n",
    "                                    \"Mean_Precision\": round(cv_results['test_precision'].mean(), 4),\n",
    "                                    \"Std_Precision\": round(cv_results['test_precision'].std(), 4),\n",
    "                                    \"Mean_Recall\": round(cv_results['test_recall'].mean(), 4),\n",
    "                                    \"Std_Recall\": round(cv_results['test_recall'].std(), 4),\n",
    "                                    \"Mean_F1-score\": round(cv_results['test_f1'].mean(), 4),\n",
    "                                    \"Std_F1-score\": round(cv_results['test_f1'].std(), 4)}])], ignore_index=True)\n",
    "# Save the results to a CSV file\n",
    "#res_path = '/content/drive/MyDrive/Data_Mining_Project/Results/'\n",
    "res_path = 'Results/'\n",
    "results_df.to_csv(res_path + 'model_results_macro.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** SVC(class_weight='balanced') *****************\n",
      "Accuracy: 0.5420\n",
      "Precision: 0.5770\n",
      "Recall: 0.5784\n",
      "F1-score: 0.5419\n"
     ]
    }
   ],
   "source": [
    "# DO NOT TOUCH 2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "list_of_models2 = [SVC(class_weight='balanced')]\n",
    "\n",
    "for model in list_of_models2:\n",
    "    print(f\"*************** {model} *****************\")\n",
    "    cv_results = cross_validate(model, X_train, y_train, cv=5, scoring=['f1', 'precision', 'recall', 'accuracy'])\n",
    "    y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "    # Evaluate model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([{'Model': str(model), 'Test Accuracy': round(accuracy, 4),\n",
    "                                    \"Test Precision\": round(precision, 4), \"Test Recall\": round(recall, 4),\n",
    "                                    \"Test F1-score\": round(f1, 4),\n",
    "                                    \"Mean_Accuracy\": round(cv_results['test_accuracy'].mean(), 4),\n",
    "                                    \"Std_Accuracy\": round(cv_results['test_accuracy'].std(), 4),\n",
    "                                    \"Mean_Precision\": round(cv_results['test_precision'].mean(), 4),\n",
    "                                    \"Std_Precision\": round(cv_results['test_precision'].std(), 4),\n",
    "                                    \"Mean_Recall\": round(cv_results['test_recall'].mean(), 4),\n",
    "                                    \"Std_Recall\": round(cv_results['test_recall'].std(), 4),\n",
    "                                    \"Mean_F1-score\": round(cv_results['test_f1'].mean(), 4),\n",
    "                                    \"Std_F1-score\": round(cv_results['test_f1'].std(), 4)}])], ignore_index=True)\n",
    "# Save the results to a CSV file\n",
    "#res_path = '/content/drive/MyDrive/Data_Mining_Project/Results/'\n",
    "res_path = 'Results/'\n",
    "results_df.to_csv(res_path + 'model_results_macro.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -1\n",
      "1   -1\n",
      "2    1\n",
      "Name: outcome, dtype: int64\n",
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = np.where(y_train == -1, 0.0, 1.0)  # Convert -1 to 0\n",
    "y_test = np.where(y_test == -1, 0.0, 1.0)    # Convert -1 to 0\n",
    "\n",
    "print(y_train_bu[:3])\n",
    "print(y_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1.]\n",
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "X_train_bu = X_train.copy()\n",
    "X_test_bu = X_test.copy\n",
    "y_train_bu = y_train.copy()\n",
    "y_test_bu = y_test.copy()\n",
    "\n",
    "print(y_train_bu[:3])\n",
    "print(y_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "\n",
    "def select_model(num):\n",
    "    global model\n",
    "    if num == 1:\n",
    "        model = Sequential([\n",
    "                    Dense(512, input_shape=(763,), activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(256, activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(128, activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(64, activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "                ])\n",
    "    elif num == 2:\n",
    "        model = Sequential([\n",
    "                    Dense(256, input_shape=(763,), activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(128, activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(64, activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "                ])\n",
    "    elif num == 3:\n",
    "        model = Sequential([\n",
    "                    Dense(256, input_shape=(763,), activation='relu'),\n",
    "                    BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(128, activation='relu'),\n",
    "                    BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(64, activation='relu'),\n",
    "                    BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "                ])\n",
    "\n",
    "    elif num == 4:\n",
    "        model = Sequential([\n",
    "                    Dense(128, input_shape=(763,), activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(64, activation='relu'),\n",
    "                    #BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "                ])\n",
    "    elif num == 5:\n",
    "        model = Sequential([\n",
    "                    Dense(128, input_shape=(763,), activation='relu'),\n",
    "                    BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(64, activation='relu'),\n",
    "                    BatchNormalization(),  # Batch Normalization layer after Dense layer\n",
    "                    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the time-limitation, we do not use cross-validation for the neural nets. Instead, we use the validation set (with the ratio of 0.2) to find the best model and prevent overfitting.\n",
    "\n",
    "#%tensorboard --logdir logs..../fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "eyxunF1RIYk7",
    "outputId": "2d68d22d-e594-4ade-dcb3-f2735829a808",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning rate schedule function.\"\"\"\n",
    "    initial_lr = 0.001\n",
    "    if epoch < epochs / 4:\n",
    "        return initial_lr\n",
    "    else:\n",
    "        return initial_lr * np.exp(-0.1 * epoch)\n",
    "\n",
    "# Splitting data into training and validation sets\n",
    "\n",
    "\n",
    "\n",
    "def train_NN(mod_num):\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    for a_seed in range(100, 111):\n",
    "        np.random.seed(a_seed)\n",
    "        seed(a_seed)\n",
    "        select_model(mod_num)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_bu, y_train_bu, test_size=0.2, random_state=a_seed)\n",
    "        \n",
    "        lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                               tf.keras.metrics.Precision(name='precision'),\n",
    "                               tf.keras.metrics.Recall(name='recall'),\n",
    "                               tf.keras.metrics.F1Score(name='f1_score', average='macro')])\n",
    "        \n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), verbose=False,\n",
    "                            callbacks=[lr_scheduler])\n",
    "\n",
    "        loss, accuracy, precision, recall, f1_score = model.evaluate(X_val, y_val)\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1_score)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Retrain and Evaluate the model\n",
    "    # Clear log directory if it exists\n",
    "    log_dir = \"logs_ModelNum\" + str(mod_num) + \"/fit/\"\n",
    "    if os.path.exists(log_dir):\n",
    "        shutil.rmtree(log_dir)\n",
    "    os.makedirs(log_dir)\n",
    "    sm_checkpoint = tf.keras.callbacks.ModelCheckpoint(res_path + 'checkpoints/best_model_' + str(mod_num) + '.h5', \n",
    "                                \t\t\t\t\t\t\tmonitor='val_f1_score', verbose=0, \n",
    "                                \t\t\t\t\t\t\tsave_best_only=True, mode='max')\n",
    "    # Define TensorBoard callback\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    select_model(mod_num)\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                               tf.keras.metrics.Precision(name='precision'),\n",
    "                               tf.keras.metrics.Recall(name='recall'),\n",
    "                               tf.keras.metrics.F1Score(name='f1_score', average='macro')])\n",
    "\n",
    "    model.summary()\n",
    "    history = model.fit(X_train_bu, y_train_bu, epochs=epochs, validation_data=(X_test, y_test), verbose=False,\n",
    "                            callbacks=[tensorboard_callback, lr_scheduler, sm_checkpoint])\n",
    "\n",
    "    loss, accuracy, precision, recall, f1_score = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    print(f'Test Loss: {loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test Precision: {precision:.4f}')\n",
    "    print(f'Test Recall: {recall:.4f}')\n",
    "    print(f'Test F1 Score: {f1_score:.4f}')\n",
    "    print()\n",
    "    print(\"From Cross_validation:\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy_list):.4f}, std: {np.std(accuracy_list):.4f}\")\n",
    "    print(f\"Precision: {np.mean(precision_list):.4f}, std: {np.std(precision_list):.4f}\")\n",
    "    print(f\"Recall: {np.mean(recall_list):.4f}, std: {np.std(recall_list):.4f}\")\n",
    "    print(f\"F1-Score: {np.mean(f1_score_list):.4f}, std: {np.std(f1_score_list):.4f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834/834 [==============================] - 1s 1ms/step - loss: 4.9770 - accuracy: 0.5732 - precision: 0.4105 - recall: 0.4058 - f1_score: 0.5630\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 4.9566 - accuracy: 0.5788 - precision: 0.4077 - recall: 0.3923 - f1_score: 0.5575\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.0519 - accuracy: 0.5719 - precision: 0.4125 - recall: 0.4056 - f1_score: 0.5659\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.3663 - accuracy: 0.5806 - precision: 0.4172 - recall: 0.4117 - f1_score: 0.5575\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.2946 - accuracy: 0.5818 - precision: 0.4142 - recall: 0.3931 - f1_score: 0.5593\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.4266 - accuracy: 0.5775 - precision: 0.4144 - recall: 0.4108 - f1_score: 0.5590\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.1656 - accuracy: 0.5734 - precision: 0.4082 - recall: 0.4156 - f1_score: 0.5611\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.4548 - accuracy: 0.5748 - precision: 0.4053 - recall: 0.3990 - f1_score: 0.5518\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.4716 - accuracy: 0.5764 - precision: 0.4061 - recall: 0.3851 - f1_score: 0.5549\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.1997 - accuracy: 0.5812 - precision: 0.4152 - recall: 0.4039 - f1_score: 0.5631\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 5.6121 - accuracy: 0.5703 - precision: 0.3967 - recall: 0.3895 - f1_score: 0.5492\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_104 (Dense)           (None, 512)               391168    \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 563713 (2.15 MB)\n",
      "Trainable params: 563713 (2.15 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/664 [==============================] - 1s 1ms/step - loss: 4.7983 - accuracy: 0.5692 - precision: 0.4181 - recall: 0.4474 - f1_score: 0.5636\n",
      "Test Loss: 4.7983\n",
      "Test Accuracy: 0.5692\n",
      "Test Precision: 0.4181\n",
      "Test Recall: 0.4474\n",
      "Test F1 Score: 0.5636\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.5763, std: 0.0038\n",
      "Precision: 0.4098, std: 0.0056\n",
      "Recall: 0.4011, std: 0.0095\n",
      "F1-Score: 0.5584, std: 0.0048\n"
     ]
    }
   ],
   "source": [
    "train_NN(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834/834 [==============================] - 1s 1ms/step - loss: 3.8274 - accuracy: 0.5791 - precision: 0.4157 - recall: 0.3960 - f1_score: 0.5665\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.7227 - accuracy: 0.5837 - precision: 0.4174 - recall: 0.4144 - f1_score: 0.5632\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.8186 - accuracy: 0.5793 - precision: 0.4186 - recall: 0.3901 - f1_score: 0.5699\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.6063 - accuracy: 0.5827 - precision: 0.4176 - recall: 0.3994 - f1_score: 0.5677\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.8669 - accuracy: 0.5712 - precision: 0.3999 - recall: 0.3838 - f1_score: 0.5644\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.8768 - accuracy: 0.5756 - precision: 0.4096 - recall: 0.3969 - f1_score: 0.5673\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.6716 - accuracy: 0.5753 - precision: 0.4080 - recall: 0.4030 - f1_score: 0.5684\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.6995 - accuracy: 0.5792 - precision: 0.4110 - recall: 0.4020 - f1_score: 0.5659\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.3267 - accuracy: 0.5779 - precision: 0.4086 - recall: 0.3889 - f1_score: 0.5714\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.7247 - accuracy: 0.5779 - precision: 0.4134 - recall: 0.4159 - f1_score: 0.5664\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 3.7933 - accuracy: 0.5743 - precision: 0.3996 - recall: 0.3809 - f1_score: 0.5624\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_153 (Dense)           (None, 256)               195584    \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 236801 (925.00 KB)\n",
      "Trainable params: 236801 (925.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/664 [==============================] - 1s 1ms/step - loss: 3.1856 - accuracy: 0.5681 - precision: 0.4223 - recall: 0.4836 - f1_score: 0.5717\n",
      "Test Loss: 3.1856\n",
      "Test Accuracy: 0.5681\n",
      "Test Precision: 0.4223\n",
      "Test Recall: 0.4836\n",
      "Test F1 Score: 0.5717\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.5778, std: 0.0034\n",
      "Precision: 0.4109, std: 0.0063\n",
      "Recall: 0.3974, std: 0.0107\n",
      "F1-Score: 0.5667, std: 0.0026\n"
     ]
    }
   ],
   "source": [
    "train_NN(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834/834 [==============================] - 1s 1ms/step - loss: 1.1193 - accuracy: 0.5798 - precision: 0.4148 - recall: 0.3866 - f1_score: 0.5323\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.1196 - accuracy: 0.5823 - precision: 0.4134 - recall: 0.4004 - f1_score: 0.5269\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.1187 - accuracy: 0.5769 - precision: 0.4134 - recall: 0.3775 - f1_score: 0.5351\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.0878 - accuracy: 0.5800 - precision: 0.4130 - recall: 0.3920 - f1_score: 0.5299\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.1258 - accuracy: 0.5803 - precision: 0.4116 - recall: 0.3889 - f1_score: 0.5291\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.1207 - accuracy: 0.5818 - precision: 0.4186 - recall: 0.4064 - f1_score: 0.5307\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.1136 - accuracy: 0.5796 - precision: 0.4098 - recall: 0.3859 - f1_score: 0.5288\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.0950 - accuracy: 0.5794 - precision: 0.4082 - recall: 0.3858 - f1_score: 0.5277\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.1444 - accuracy: 0.5734 - precision: 0.4007 - recall: 0.3762 - f1_score: 0.5290\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.1138 - accuracy: 0.5809 - precision: 0.4148 - recall: 0.4039 - f1_score: 0.5289\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.1268 - accuracy: 0.5750 - precision: 0.3996 - recall: 0.3770 - f1_score: 0.5265\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_201 (Dense)           (None, 256)               195584    \n",
      "                                                                 \n",
      " batch_normalization_38 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_39 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_40 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238593 (932.00 KB)\n",
      "Trainable params: 237697 (928.50 KB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/664 [==============================] - 1s 1ms/step - loss: 1.0276 - accuracy: 0.5673 - precision: 0.4153 - recall: 0.4420 - f1_score: 0.5365\n",
      "Test Loss: 1.0276\n",
      "Test Accuracy: 0.5673\n",
      "Test Precision: 0.4153\n",
      "Test Recall: 0.4420\n",
      "Test F1 Score: 0.5365\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.5790, std: 0.0027\n",
      "Precision: 0.4107, std: 0.0056\n",
      "Recall: 0.3891, std: 0.0101\n",
      "F1-Score: 0.5295, std: 0.0024\n"
     ]
    }
   ],
   "source": [
    "train_NN(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834/834 [==============================] - 1s 837us/step - loss: 1.0972 - accuracy: 0.5768 - precision: 0.4100 - recall: 0.3802 - f1_score: 0.5798\n",
      "834/834 [==============================] - 1s 885us/step - loss: 1.1028 - accuracy: 0.5772 - precision: 0.4009 - recall: 0.3684 - f1_score: 0.5749\n",
      "834/834 [==============================] - 1s 856us/step - loss: 1.1286 - accuracy: 0.5755 - precision: 0.4127 - recall: 0.3834 - f1_score: 0.5825\n",
      "834/834 [==============================] - 1s 789us/step - loss: 1.0844 - accuracy: 0.5837 - precision: 0.4159 - recall: 0.3829 - f1_score: 0.5768\n",
      "834/834 [==============================] - 1s 793us/step - loss: 1.1401 - accuracy: 0.5803 - precision: 0.4068 - recall: 0.3648 - f1_score: 0.5779\n",
      "834/834 [==============================] - 1s 1ms/step - loss: 1.0975 - accuracy: 0.5752 - precision: 0.4065 - recall: 0.3831 - f1_score: 0.5792\n",
      "834/834 [==============================] - 1s 932us/step - loss: 1.1092 - accuracy: 0.5741 - precision: 0.4031 - recall: 0.3850 - f1_score: 0.5773\n",
      "834/834 [==============================] - 1s 858us/step - loss: 1.0877 - accuracy: 0.5786 - precision: 0.4097 - recall: 0.3985 - f1_score: 0.5755\n",
      "834/834 [==============================] - 1s 900us/step - loss: 1.1103 - accuracy: 0.5766 - precision: 0.4056 - recall: 0.3812 - f1_score: 0.5765\n",
      "834/834 [==============================] - 1s 833us/step - loss: 1.1020 - accuracy: 0.5872 - precision: 0.4198 - recall: 0.3880 - f1_score: 0.5777\n",
      "834/834 [==============================] - 1s 805us/step - loss: 1.1227 - accuracy: 0.5782 - precision: 0.4014 - recall: 0.3678 - f1_score: 0.5745\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_238 (Dense)           (None, 128)               97792     \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_240 (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106113 (414.50 KB)\n",
      "Trainable params: 106113 (414.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/664 [==============================] - 1s 817us/step - loss: 1.0812 - accuracy: 0.5770 - precision: 0.4211 - recall: 0.4102 - f1_score: 0.5791\n",
      "Test Loss: 1.0812\n",
      "Test Accuracy: 0.5770\n",
      "Test Precision: 0.4211\n",
      "Test Recall: 0.4102\n",
      "Test F1 Score: 0.5791\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.5785, std: 0.0037\n",
      "Precision: 0.4084, std: 0.0057\n",
      "Recall: 0.3803, std: 0.0094\n",
      "F1-Score: 0.5775, std: 0.0022\n"
     ]
    }
   ],
   "source": [
    "train_NN(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834/834 [==============================] - 1s 842us/step - loss: 0.8925 - accuracy: 0.5791 - precision: 0.4143 - recall: 0.3882 - f1_score: 0.5323\n",
      "834/834 [==============================] - 1s 821us/step - loss: 0.8859 - accuracy: 0.5830 - precision: 0.4097 - recall: 0.3767 - f1_score: 0.5269\n",
      "834/834 [==============================] - 1s 804us/step - loss: 0.8882 - accuracy: 0.5821 - precision: 0.4184 - recall: 0.3695 - f1_score: 0.5351\n",
      "834/834 [==============================] - 1s 824us/step - loss: 0.8938 - accuracy: 0.5839 - precision: 0.4128 - recall: 0.3648 - f1_score: 0.5299\n",
      "834/834 [==============================] - 1s 957us/step - loss: 0.9048 - accuracy: 0.5824 - precision: 0.4084 - recall: 0.3592 - f1_score: 0.5290\n",
      "834/834 [==============================] - 1s 946us/step - loss: 0.8933 - accuracy: 0.5807 - precision: 0.4124 - recall: 0.3788 - f1_score: 0.5307\n",
      "834/834 [==============================] - 1s 918us/step - loss: 0.8937 - accuracy: 0.5781 - precision: 0.4064 - recall: 0.3779 - f1_score: 0.5288\n",
      "834/834 [==============================] - 1s 927us/step - loss: 0.8779 - accuracy: 0.5893 - precision: 0.4196 - recall: 0.3806 - f1_score: 0.5277\n",
      "834/834 [==============================] - 1s 878us/step - loss: 0.9090 - accuracy: 0.5797 - precision: 0.4078 - recall: 0.3737 - f1_score: 0.5290\n",
      "834/834 [==============================] - 1s 893us/step - loss: 0.9013 - accuracy: 0.5829 - precision: 0.4109 - recall: 0.3697 - f1_score: 0.5289\n",
      "834/834 [==============================] - 1s 887us/step - loss: 0.8968 - accuracy: 0.5809 - precision: 0.4047 - recall: 0.3673 - f1_score: 0.5265\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_274 (Dense)           (None, 128)               97792     \n",
      "                                                                 \n",
      " batch_normalization_63 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_64 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_276 (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106881 (417.50 KB)\n",
      "Trainable params: 106497 (416.00 KB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python-3.11.4\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/664 [==============================] - 1s 852us/step - loss: 0.8093 - accuracy: 0.5749 - precision: 0.4155 - recall: 0.3921 - f1_score: 0.5365\n",
      "Test Loss: 0.8093\n",
      "Test Accuracy: 0.5749\n",
      "Test Precision: 0.4155\n",
      "Test Recall: 0.3921\n",
      "Test F1 Score: 0.5365\n",
      "\n",
      "From Cross_validation:\n",
      "Accuracy: 0.5820, std: 0.0029\n",
      "Precision: 0.4114, std: 0.0045\n",
      "Recall: 0.3733, std: 0.0078\n",
      "F1-Score: 0.5295, std: 0.0024\n"
     ]
    }
   ],
   "source": [
    "train_NN(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "1Oc9esJaCTf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834/834 [==============================] - 1s 731us/step\n",
      "Accuracy: 0.5801\n",
      "Precision: 0.4022\n",
      "Recall: 0.3989\n",
      "F1-score: 0.4006\n"
     ]
    }
   ],
   "source": [
    "# Leave it (not important)\n",
    "\n",
    "\n",
    "import sklearn\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.where(y_pred >= 0.5, 1, 0)\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = sklearn.metrics.f1_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
